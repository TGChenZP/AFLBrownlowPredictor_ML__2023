{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Crawling AFL Match Player Data from FootyWire.com #\n",
    "## For Brownlow Predictor Project ##\n",
    "\n",
    "This notebook scrapes statistics and brownlow votes of AFL games from FootyWire.com\n",
    "\n",
    "**Author: `Lang (Ron) Chen` 2021.12-2022.1**\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from urllib.parse import urljoin\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Scrape Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url):\n",
    "    \"\"\" Function which scrapes the given FootyWire webpage \"\"\"\n",
    "    \n",
    "    # Scrape first page\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    section = soup.find(id='contentpagecell')\n",
    "    results = section.findNext('table')\n",
    "    rows = results.find_all('tr')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Check that this is a Home and Away game rather than finals. If not then just stop the process\n",
    "    findround = section.findNext('table').findNext('table').findNext('table')\n",
    "    if not bool(re.search(r'Round', str(findround))):\n",
    "        return False, False, False    # because our normal return returns three objects\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get Brownlow votes data (but input is later)\n",
    "    brownlow = list() #Mechanism to prevent non-assignment because some pages don't have bronwlow data\n",
    "    for i in range(len(rows)):\n",
    "        if re.search(r'Brownlow Votes:', str(rows[i])):\n",
    "            brownlow = rows[i]\n",
    "    if brownlow:\n",
    "        players = brownlow.find_all('a')\n",
    "        brownlow = list()\n",
    "        for player in players:\n",
    "            brownlow.append(re.findall(r'>. .+<', str(player))[0].strip('<>'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get raw player statistics\n",
    "    results = soup.find(id='matchscoretable').findNext('table')\n",
    "    rows=results.find_all('tr')\n",
    "   \n",
    "    tick = 0\n",
    "    for i in range(1, len(rows)): # recent update of website: 0th item is a table of both teams - messes up our structure\n",
    "        if not tick and len(rows[i].find_all('tr'))>24: # From experiment, blocks that contain player data (what we want) has more than 25 rows\n",
    "            team1stats=rows[i]\n",
    "            tick=1\n",
    "        elif len(rows[i].find_all('tr'))>24:\n",
    "            team2stats=rows[i]\n",
    "            break\n",
    "            \n",
    "    team1playerstats = team1stats.find_all('tr')[2].find_all('tr') # From experimenting with scraped blob\n",
    "    team2playerstats = team2stats.find_all('tr')[2].find_all('tr')\n",
    "\n",
    "    gamestatscol1 = getdata(team1playerstats)\n",
    "    gamestatscol2 = getdata(team2playerstats)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get advanced player statistics\n",
    "    time.sleep(random.uniform(0.1, 0.5))    # First sleep for a random amount of time - trying to hide crawler activity\n",
    "    \n",
    "    urlAdv = url + '&advv=Y' # Because advanced statistic's URL is only different from orig URL by this string\n",
    "    pageAdv = requests.get(urlAdv)\n",
    "    soupAdv = BeautifulSoup(pageAdv.text, 'html.parser')\n",
    "    \n",
    "    resultsAdv = soupAdv.find(id='matchscoretable').findNext('table')\n",
    "    rowsAdv=resultsAdv.find_all('tr')\n",
    "\n",
    "    tick = 0\n",
    "    for i in range(1, len(rowsAdv)): # recent update of website: 0th item is a table of both teams - messes up our structure\n",
    "        if not tick and len(rowsAdv[i].find_all('tr'))>24:\n",
    "            team1stats=rowsAdv[i]\n",
    "            tick=1\n",
    "        elif len(rowsAdv[i].find_all('tr'))>24:\n",
    "            team2stats=rowsAdv[i]\n",
    "            break  \n",
    "    \n",
    "    team1playerstats = team1stats.find_all('tr')[2].find_all('tr')\n",
    "    team2playerstats = team2stats.find_all('tr')[2].find_all('tr')\n",
    "    \n",
    "    gamestatscol1A = getadvdata(team1playerstats)\n",
    "    gamestatscol2A = getadvdata(team2playerstats)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Append the advanced player statistics to standard player statistics\n",
    "    origattb1 = list()\n",
    "    \n",
    "    for i in range(len(gamestatscol1)):\n",
    "        origattb1.append(gamestatscol1[i][0])\n",
    "\n",
    "    for i in range(len(gamestatscol1A)):\n",
    "        if gamestatscol1A[i][0] not in origattb1:\n",
    "            gamestatscol1.append(gamestatscol1A[i])\n",
    "            \n",
    "            \n",
    "    origattb2 = list()\n",
    "    for i in range(len(gamestatscol2)):\n",
    "        origattb2.append(gamestatscol2[i][0])\n",
    "\n",
    "    for i in range(len(gamestatscol2A)):\n",
    "        if gamestatscol2A[i][0] not in origattb2:\n",
    "            gamestatscol2.append(gamestatscol2A[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Find Winloss data and also records whether a player is from the home team or away team (helps manipulate stats by own team later)\n",
    "    winloss = section.findNext('table').findNext('table').findNext('table') \n",
    "    keyword = re.findall(r'>\\n.*\\n<', str(winloss.find_all('td')[0]))[0].strip('>\\n\\n<')\n",
    "\n",
    "    v1 = int()\n",
    "    v2 = int()\n",
    "\n",
    "    if 'defeats' in keyword:\n",
    "        v1 = 1\n",
    "        v2 = 0\n",
    "    elif 'defeated by' in keyword:\n",
    "        v1 = 0\n",
    "        v2 = 1\n",
    "    else:\n",
    "        v1 = 0.5\n",
    "        v2 = 0.5\n",
    "    \n",
    "    winloss1 = ['Winloss']\n",
    "    winloss2 = ['Winloss']\n",
    "    homeaway1 = ['HomeAway']\n",
    "    homeaway2 = ['HomeAway']\n",
    "    for i in range(1, len(gamestatscol1[0])):\n",
    "        winloss1.append(v1)\n",
    "        homeaway1.append('Home')\n",
    "    for i in range(1, len(gamestatscol2[0])):\n",
    "        winloss2.append(v2)\n",
    "        homeaway2.append('Away')\n",
    "    \n",
    "    gamestatscol1.append(winloss1)\n",
    "    gamestatscol2.append(winloss2)\n",
    "    \n",
    "    gamestatscol1.append(homeaway1)\n",
    "    gamestatscol2.append(homeaway2)\n",
    "    \n",
    "\n",
    "    # Collect some statistics for naming the file such as year, round, and team names (collectively metadata)\n",
    "    Year = re.findall(r'\\d{4},', str(winloss))[0].strip(',')\n",
    "    Round = re.findall(r'Round \\d+', str(winloss))[0]\n",
    "    \n",
    "    team1 = keyword.split()[0]\n",
    "    # Hardcoded some of the two worded team names\n",
    "    if team1 == 'Gold':\n",
    "        team1 = 'GoldCoast'\n",
    "    \n",
    "    elif team1 == 'North':\n",
    "        team1 = 'NorthMelbourne'\n",
    "    \n",
    "    elif team1 == 'Port':\n",
    "        team1 = 'PortAdelaide'\n",
    "    \n",
    "    elif team1 == 'St':\n",
    "        team1 = 'StKilda'\n",
    "    \n",
    "    elif team1 == 'West':\n",
    "        team1 = 'WestCoast'\n",
    "    \n",
    "    elif team1 == 'Western':\n",
    "        team1 = 'WesternBulldogs'\n",
    "    \n",
    "    \n",
    "    team2 = keyword.split()[-1]\n",
    "    if team2 == 'Coast': \n",
    "        if keyword.split()[-2] == 'Gold':\n",
    "            team2 = 'GoldCoast'\n",
    "        elif keyword.split()[-2] == 'West':\n",
    "            team2 = 'WestCoast'\n",
    "    \n",
    "    elif team2 == 'Melbourne' and keyword.split()[-2] == 'North':\n",
    "        team2 = 'NorthMelbourne'\n",
    "    \n",
    "    elif team2 == 'Adelaide' and keyword.split()[-2] == 'Port':\n",
    "        team2 = 'PortAdelaide'\n",
    "    \n",
    "    elif team2 == 'Kilda':\n",
    "        team2 = 'StKilda'\n",
    "        \n",
    "    elif team2 == 'Bulldogs':\n",
    "        team2 = 'WesternBulldogs'\n",
    "\n",
    "    \n",
    "    \n",
    "    # Add Brownlow Data into our dataframe as a column\n",
    "    team1playerlist = gamestatscol1[0]\n",
    "    team2playerlist = gamestatscol2[0]\n",
    "    \n",
    "    if brownlow:\n",
    "        brownlow[0] = shorten_surname(brownlow[0])\n",
    "        brownlow[1] = shorten_surname(brownlow[1])\n",
    "        brownlow[2] = shorten_surname(brownlow[2])\n",
    "        \n",
    "        brownlowdict = {brownlow[0]: 3, brownlow[1]:2, brownlow[2]: 1}\n",
    "    else:\n",
    "        brownlowdict = dict()\n",
    "    \n",
    "    brownlowteam1 = list()\n",
    "    brownlowteam1.append('Brownlow Votes')\n",
    "    for i in range(1, len(team1playerlist)):\n",
    "        if nametransf(team1playerlist[i]) in brownlowdict:\n",
    "            brownlowteam1.append(brownlowdict[nametransf(team1playerlist[i])])\n",
    "        else:\n",
    "            brownlowteam1.append(0)\n",
    "    gamestatscol1.append(brownlowteam1)\n",
    "\n",
    "    brownlowteam2 = list()\n",
    "    brownlowteam2.append('Brownlow Votes')\n",
    "    for i in range(1, len(team2playerlist)):\n",
    "        if nametransf(team2playerlist[i]) in brownlowdict:\n",
    "            brownlowteam2.append(brownlowdict[nametransf(team2playerlist[i])])\n",
    "        else:\n",
    "            brownlowteam2.append(0)\n",
    "    gamestatscol2.append(brownlowteam2)\n",
    "    \n",
    "    \n",
    "    # Print games where there is an error in Brownlow Votes (i.e. Total brownlow votes does not add up to 1+2+3 = 6)\n",
    "    # This is a warning mechanism\n",
    "    if (sum(brownlowteam1[1:]) + sum(brownlowteam2[1:])) != 6:\n",
    "        print(f'{Year} {Round} {team1} v {team2}: {sum(brownlowteam1[1:]) + sum(brownlowteam2[1:])}')\n",
    "        if brownlow:\n",
    "            print(brownlowdict)\n",
    "        print('\\n')\n",
    "    \n",
    "    \n",
    "    return gamestatscol1, gamestatscol2, (Year, Round, team1, team2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_surname(name):\n",
    "    \"\"\" Function to change compound surname into semi-initials format to fit the player name data on FootyWire.com \"\"\"\n",
    "    \n",
    "    if '-' in name.split()[1]:\n",
    "        surname_lst = name.split()[1].split('-')\n",
    "        new_surname = f'{surname_lst[0][0]}-{surname_lst[1]}'\n",
    "        return f'{name.split()[0]} {new_surname}'\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(teamplayerstats):\n",
    "    \"\"\" Function which manipulates scraped data and puts them into a suitable list format for further wrangling\"\"\"\n",
    "    \n",
    "    gamestatsrow = list()\n",
    "    for row in teamplayerstats:\n",
    "        record = list()\n",
    "        cells = row.find_all('td')\n",
    "        for cell in cells:\n",
    "            record.append(re.findall(r'>.*<', str(cell))[0].strip('><'))\n",
    "        gamestatsrow.append(record)\n",
    "\n",
    "        \n",
    "    # Add player name    \n",
    "    gamestatscol = list()\n",
    "    tmp = list()\n",
    "    for i in range(len(gamestatsrow)):\n",
    "        tmp.append(re.findall(r'>.*<',gamestatsrow[i][0])[0].strip('><').split('<')[0])\n",
    "    gamestatscol.append(tmp)\n",
    "\n",
    "    \n",
    "    # Add other stats\n",
    "    unused_sub = 0\n",
    "    for i in range(1,16):    # Hardcoded\n",
    "        tmp = list()\n",
    "\n",
    "        if i == 1:\n",
    "            for j in range(len(gamestatsrow)):\n",
    "                if j == 0:\n",
    "                    tmp.append(re.findall(r'title=\".*\"', str(gamestatsrow[0][i]))[0].strip('title=\"\"'))\n",
    "                elif gamestatsrow[j][i] == 'Unused Substitute':\n",
    "                    gamestatscol[0] = gamestatscol[0][:-1]\n",
    "                    unused_sub = 1\n",
    "                else:\n",
    "                    tmp.append(float(gamestatsrow[j][i]))\n",
    "\n",
    "        else:\n",
    "            n_players_used = len(gamestatsrow)\n",
    "            if unused_sub:\n",
    "                n_players_used = len(gamestatsrow)-1\n",
    "\n",
    "            for j in range(n_players_used):\n",
    "                if j == 0:\n",
    "                    tmp.append(re.findall(r'title=\".*\"', str(gamestatsrow[0][i]))[0].strip('title=\"\"'))\n",
    "                else:\n",
    "                    tmp.append(float(gamestatsrow[j][i]))\n",
    "\n",
    "\n",
    "        gamestatscol.append(tmp)\n",
    "    \n",
    "    \n",
    "    return gamestatscol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getadvdata(teamplayerstats):\n",
    "    \"\"\" Function which manipulates scraped advanced data and puts them into a suitable list format for further wrangling\"\"\"\n",
    "    \n",
    "    gamestatsrow = list()\n",
    "    for row in teamplayerstats:\n",
    "        record = list()\n",
    "        cells=row.find_all('td')\n",
    "        for cell in cells:\n",
    "            record.append(re.findall(r'>.*<', str(cell))[0].strip('><'))\n",
    "        gamestatsrow.append(record)\n",
    "    \n",
    "    \n",
    "    # Add player name \n",
    "    gamestatscolA = list()\n",
    "    tmp = list()\n",
    "    for i in range(len(gamestatsrow)):\n",
    "        tmp.append(re.findall(r'>.*<',gamestatsrow[i][0])[0].strip('><'))\n",
    "    gamestatscolA.append(tmp)\n",
    "\n",
    "    \n",
    "    # Add other stats\n",
    "    unused_sub = 0\n",
    "    for i in range(1,18):    # Hardcoded\n",
    "        tmp = list()\n",
    "\n",
    "        if i == 1:\n",
    "            for j in range(len(gamestatsrow)):\n",
    "                if j == 0:\n",
    "                    tmp.append(re.findall(r'title=\".*\"', str(gamestatsrow[0][i]))[0].strip('title=\"\"'))\n",
    "                elif gamestatsrow[j][i] == 'Unused Substitute':\n",
    "                    gamestatscolA[0] = gamestatscolA[0][:-1]\n",
    "                    unused_sub = 1\n",
    "                else:\n",
    "                    tmp.append(float(gamestatsrow[j][i]))\n",
    "\n",
    "        else:\n",
    "            n_players_used = len(gamestatsrow)\n",
    "            if unused_sub:\n",
    "                n_players_used = len(gamestatsrow)-1\n",
    "\n",
    "            for j in range(n_players_used):\n",
    "                if j == 0:\n",
    "                    tmp.append(re.findall(r'title=\".*\"', str(gamestatsrow[0][i]))[0].strip('title=\"\"'))\n",
    "                else:\n",
    "                    tmp.append(float(gamestatsrow[j][i]))\n",
    "\n",
    "\n",
    "        gamestatscolA.append(tmp)\n",
    "\n",
    "        \n",
    "    return gamestatscolA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nametransf(name):\n",
    "    \"\"\" For matching full player name format of original data to 'initials + last name' format of Brownlow data \"\"\"\n",
    "    \n",
    "    # Special case: sydney player Josh Kennedy who is recoreded as Josh P. Kennedy \n",
    "    if name == 'Josh P. Kennedy':\n",
    "        return 'J Kennedy'\n",
    "    \n",
    "    tmp = name.split(' ')\n",
    "    first_name = tmp[0]\n",
    "    last_name = str()\n",
    "    for i in range(1,len(tmp)):\n",
    "        last_name += tmp[i]\n",
    "        last_name += ' '\n",
    "        \n",
    "    return f'{first_name[0]} {last_name[:-1]}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Functions for saving output as CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(lst1, lst2):\n",
    "    \"\"\" Function to join the two team's lists into one so we could put into dataframe and save \"\"\"\n",
    "    \n",
    "    out = list()\n",
    "    for i in range(len(lst1)):\n",
    "        out.append(list())\n",
    "        for j in range(len(lst1[i])):\n",
    "            out[i].append(lst1[i][j])\n",
    "    for i in range(len(lst1)):\n",
    "        for j in range(1,len(lst2[i])):\n",
    "            out[i].append(lst2[i][j])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(lst, metadata, datatype):\n",
    "    \"\"\" Function to save data in form of lists as a dataframe and then a CSV \"\"\"\n",
    "    \n",
    "    DICT = {'O': 'OriginalData'}\n",
    "    df = pd.DataFrame({lst[0][0]: lst[0][1:len(lst[0])]})\n",
    "    for i in range(1, len(lst)):\n",
    "        df.insert(column = lst[i][0], value = lst[i][1:len(lst[0])], loc = i)\n",
    "    \n",
    "    if not os.path.exists(f'../data/raw/{DICT[datatype]}'):\n",
    "            os.makedirs(f'../data/raw/{DICT[datatype]}')\n",
    "    \n",
    "    df.to_csv(f'../data/raw/{DICT[datatype]}/{metadata[0]} {metadata[1]} {metadata[2]} v {metadata[3]} ({datatype}).csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crawl and Scrape ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crawling the urls which contain the player data of each game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.footywire.com/afl/footy/'\n",
    "years = range(2022, 2024)\n",
    "\n",
    "# years = list(range(2015,2022)) # the years we are interested in\n",
    "urllist = list()\n",
    "\n",
    "for year in years:\n",
    "    u = f'https://www.footywire.com/afl/footy/ft_match_list?year={year}'\n",
    "    page = requests.get(u)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    sections = soup.find_all('a')\n",
    "    gameurl = list()\n",
    "    for section in sections:\n",
    "        if re.search(r'>\\d*-\\d*<', str(section)):\n",
    "            gameurl.append(urljoin(base_url, section['href']))\n",
    "    urllist.append(gameurl)\n",
    "    \n",
    "    time.sleep(random.uniform(0.1, 0.5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping every game in the given years using a loop.\n",
    "\n",
    "*(This is like the overall 'Main' function in this entire notebook)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 Round 6 WesternBulldogs v Adelaide: 7\n",
      "{'T Walker': 3, \"R O'Brien\": 2, 'B Smith': 1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for year in urllist:\n",
    "    for game in year:\n",
    "        test1, test2, metadata = scrape(game)\n",
    "        \n",
    "        if test1 != False and test2 != False and metadata != False:\n",
    "            out = combine(test1, test2)\n",
    "            save(out, metadata, 'O')\n",
    "        \n",
    "        time.sleep(random.uniform(0.1, 0.5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: A few improvements could be made on this notebook: ##\n",
    "\n",
    "*1. The crawler lacks a list to contain visited sites, and the most glaring implication is that if the looped scraping fails at a certain game, all previous games (at least in that year) needs to be re-scraped*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
