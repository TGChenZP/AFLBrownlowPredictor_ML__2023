{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08/01/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as s\n",
    "import copy\n",
    "import time\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import t\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YangZhou:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialise class \"\"\"\n",
    "        self._initialise_objects()\n",
    "\n",
    "        print('YangZhou Initialised')\n",
    "\n",
    "\n",
    "\n",
    "    def _initialise_objects(self):\n",
    "        \"\"\" Helper to initialise objects \"\"\"\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.val_x = None\n",
    "        self.val_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "        self.tuning_result = None\n",
    "        self.model = None\n",
    "        self.parameter_choices = None\n",
    "        self.hyperparameters = None\n",
    "        self.checked = None\n",
    "        self.result = None\n",
    "        self.checked_core = None\n",
    "        self.been_best = None\n",
    "        self.been_cruised = None\n",
    "        self.tuning_result_saving_address = None\n",
    "        self.object_saving_address = None\n",
    "        self._parameter_value_map_index = None\n",
    "        self._seed = 19260817\n",
    "        self.best_score = -np.inf\n",
    "        self.best_combo = None\n",
    "        self.best_clf = None\n",
    "        self.clf_type = None\n",
    "        self.n_items = None\n",
    "        self._core = None\n",
    "        self._cruise_indices = None\n",
    "        self._cruise_indices_values = None\n",
    "        self._cruise_combinations = None\n",
    "        self._restarts = 0\n",
    "        self._cruising = True\n",
    "        self._surrounding_vectors = None\n",
    "\n",
    "        self.regression_extra_output_columns = ['Train r2', 'Val r2', 'Test r2', \n",
    "            'Train RMSE', 'Val RMSE', 'Test RMSE', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Time']\n",
    "        self.classification_extra_output_columns = ['Train accu', 'Val accu', 'Test accu', \n",
    "            'Train balanced_accu', 'Val balanced_accu', 'Test balanced_accu', 'Train f1', 'Val f1', 'Test f1', \n",
    "            'Train precision', 'Val precision', 'Test precision', 'Train recall', 'Val recall', 'Test recall', 'Time']\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_data(self, train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "        \"\"\" Reads in train validate test data for tuning \"\"\"\n",
    "\n",
    "        self.train_x = train_x\n",
    "        print(\"Read in Train X data\")\n",
    "\n",
    "        self.train_y = train_y\n",
    "        print(\"Read in Train x data\")\n",
    "\n",
    "        self.val_x = val_x\n",
    "        print(\"Read in Val X data\")\n",
    "\n",
    "        self.val_y = val_y\n",
    "        print(\"Read in Val y data\")\n",
    "\n",
    "        self.test_x = test_x\n",
    "        print(\"Read in Test X data\")\n",
    "\n",
    "        self.test_y = test_y\n",
    "        print(\"Read in Test y data\")\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_model(self, model, type):\n",
    "        \"\"\" Reads in underlying model object for tuning, and also read in what type of model it is \"\"\"\n",
    "\n",
    "        assert type == 'Classification' or type == 'Regression' # check\n",
    "\n",
    "        # record\n",
    "        self.model = model\n",
    "        self.clf_type = type \n",
    "\n",
    "        print(f'Successfully read in model {self.model}, which is a {self.clf_type} model')\n",
    "\n",
    "\n",
    "\n",
    "    def set_hyperparameters(self, parameter_choices):\n",
    "        \"\"\" Input hyperparameter choices \"\"\"\n",
    "\n",
    "        self.parameter_choices = parameter_choices\n",
    "        self._sort_hyperparameter_choices()\n",
    "\n",
    "        self.hyperparameters = list(parameter_choices.keys())\n",
    "\n",
    "        # automatically calculate how many different values in each hyperparameter\n",
    "        self.n_items = [len(parameter_choices[key]) for key in self.hyperparameters]\n",
    "        self.num_hyperparameters = {hyperparameter:len(parameter_choices[hyperparameter]) for hyperparameter in self.hyperparameters}\n",
    "\n",
    "        # automatically setup checked and result arrays and tuning result dataframe\n",
    "        self._get_checked_and_result_array()\n",
    "        self._setup_tuning_result_df()\n",
    "\n",
    "        print(\"Successfully recorded hyperparameter choices\")\n",
    "\n",
    "\n",
    "    \n",
    "    def _sort_hyperparameter_choices(self):\n",
    "        \"\"\" Helper to ensure all hyperparameter choice values are in order from lowest to highest \"\"\"\n",
    "\n",
    "        for key in self.parameter_choices:\n",
    "            tmp = copy.deepcopy(list(self.parameter_choices[key]))\n",
    "            tmp.sort()\n",
    "            self.parameter_choices[key] = tuple(tmp)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_checked_and_result_array(self):\n",
    "        \"\"\" Helper to set up checked and result array \"\"\"\n",
    "\n",
    "        self.checked = np.zeros(shape=self.n_items)\n",
    "        self.result = np.zeros(shape=self.n_items)\n",
    "        self.checked_core = np.zeros(shape=self.n_items)\n",
    "        self.been_best = np.zeros(shape=self.n_items) # strictly for last part of Guidance Algorithm\n",
    "        self.been_cruised = np.zeros(shape=self.n_items)\n",
    "\n",
    "\n",
    "\n",
    "    def _setup_tuning_result_df(self):\n",
    "        \"\"\" Helper to set up tuning result dataframe \"\"\"\n",
    "\n",
    "        tune_result_columns = copy.deepcopy(self.hyperparameters)\n",
    "\n",
    "        # Different set of metric columns for different types of models\n",
    "        if self.clf_type == 'Classification':\n",
    "            tune_result_columns.extend(self.classification_extra_output_columns)\n",
    "        elif self.clf_type == 'Regression':\n",
    "            tune_result_columns.extend(self.regression_extra_output_columns)\n",
    "\n",
    "        self.tuning_result = pd.DataFrame({col:list() for col in tune_result_columns})\n",
    "\n",
    "\n",
    "\n",
    "    def _get_core(self):\n",
    "        \"\"\" Helper to calculate core \"\"\"\n",
    "        self._core = [int(i/2) for i in self.n_items]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_combinations(self):\n",
    "        \"\"\" Helper to cruise combinations \"\"\"\n",
    "\n",
    "        self._get_cruise_indices_values()\n",
    "        self._generate_cruise_combinations() # first get cruise indicies, then use indicies to get combinations\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_indices_values(self):\n",
    "        \"\"\" Helper to get cruise indices values of each dimension which serves as building blocks for cruise combinations \"\"\"\n",
    "\n",
    "        self._cruise_indices = dict()\n",
    "        for hyperparameter in self.hyperparameters:\n",
    "            self._cruise_indices[hyperparameter] = self._get_cruise_indices_1d(d_val = self.num_hyperparameters[hyperparameter], max_jump = 5)\n",
    "\n",
    "        self._cruise_indices_values = list(self._cruise_indices.values())\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_indices_1d(self, d_val, max_jump = 5): \n",
    "        \"\"\" Helper that returns the appropriate cruise indices based on the number of values in dimension. Second argument controls maximum split size, defaulted to 5 \"\"\"\n",
    "\n",
    "        assert type(d_val) is int and type(max_jump) is int, \"Error: type of input(s) is not int\"\n",
    "        assert max_jump >= 1, \"Error: max_jump must be >= 1\"\n",
    "\n",
    "        gap = d_val - 1\n",
    "        split = ((gap-1)//max_jump)\n",
    "\n",
    "        jump = self._find_gaps(split, gap)\n",
    "\n",
    "        cruise_indices_1d = self._find_cruise_indices_1d(jump)\n",
    "\n",
    "        return cruise_indices_1d\n",
    "\n",
    "\n",
    "\n",
    "    def _find_gaps(self, split, gap):\n",
    "        \"\"\" Helper that finds the size of jumps between each element of the final cruise indices, as evenly split as possible with jump size <= 5 \"\"\"\n",
    "\n",
    "        if split > 0:\n",
    "            jump = [gap//(split+1) for i in range(split+1)]\n",
    "            diff = gap - sum(jump)\n",
    "            if diff:\n",
    "                for i in range(diff):\n",
    "                    jump[i] += 1\n",
    "        else:\n",
    "            jump = [gap]\n",
    "\n",
    "        return jump\n",
    "\n",
    "\n",
    "\n",
    "    def _find_cruise_indices_1d(self, jump):\n",
    "        \"\"\" Helper that finds the actual cruise_indices based on gaps \"\"\"\n",
    "\n",
    "        cruise_indices_1d = [0]\n",
    "        for i in range(len(jump)):\n",
    "            cruise_indices_1d.append(sum(jump[:i+1]))\n",
    "\n",
    "        if cruise_indices_1d == [0, 0]:\n",
    "            cruise_indices_1d = [0]\n",
    "            \n",
    "        return cruise_indices_1d\n",
    "\n",
    "\n",
    "\n",
    "    def _generate_cruise_combinations(self):\n",
    "        \"\"\" Helper that generates the actual cruise combinations based on cruise indicies \"\"\"\n",
    "        ##ALGORITHM: how to generate all combinations of any dimensions given each dimension has different values\n",
    "        self._cruise_combinations = [[]]\n",
    "        for i in range(len(self._cruise_indices_values)):\n",
    "\n",
    "            tmp = copy.deepcopy(self._cruise_combinations)\n",
    "            self._cruise_combinations = list()\n",
    "\n",
    "            for x in tmp:\n",
    "\n",
    "                for k in self._cruise_indices_values[i]:\n",
    "                    y = copy.deepcopy(x)\n",
    "                    \n",
    "                    y.append(k)\n",
    "\n",
    "                    self._cruise_combinations.append(y)\n",
    "\n",
    "\n",
    "\n",
    "    def _sort_cruise_combos(self, max_combo):\n",
    "        \"\"\" sort the cruise combos based on Euclidean distance from current max\"\"\"\n",
    "\n",
    "        edist = list(cdist([max_combo], self._cruise_combinations).flatten())\n",
    "        ordered_cruise_combos = [(self._cruise_combinations[i], edist[i]) for i in range(len(self._cruise_combinations))]\n",
    "\n",
    "        ordered_cruise_combos.sort(reverse=True, key=lambda x: x[1])\n",
    "\n",
    "        sorted_cruise_combos = [ordered_cruise_combos[i][0] for i in range(len(ordered_cruise_combos))]\n",
    "\n",
    "        return sorted_cruise_combos\n",
    "\n",
    "    \n",
    "\n",
    "    def _get_max_surrounding_mean_sd(self):\n",
    "        \"\"\" Helper to get the surrounding mean and sd given the current maximum \"\"\"\n",
    "\n",
    "        best_combo_surrounding_combos = self._get_surrounding_combos(self.best_combo, self._surrounding_vectors)\n",
    "        best_combo_surrounding_scores = [self.best_score]\n",
    "        for combo in best_combo_surrounding_combos:\n",
    "            best_combo_surrounding_scores.append(self.result[tuple(combo)])\n",
    "\n",
    "        max_surrounding_mean = s.mean(best_combo_surrounding_scores)\n",
    "        max_surrounding_sd = s.stdev(best_combo_surrounding_scores)\n",
    "\n",
    "        return max_surrounding_mean, max_surrounding_sd\n",
    "\n",
    "\n",
    "\n",
    "    def _cruise_warning_threshold(self, max_surrounding_mean, max_surrounding_sd, max_surrounding_n):\n",
    "        \"\"\" Helper that gets the warning threshold by (max - halfwidth) \"\"\"\n",
    "\n",
    "        # use 0.95 (one sided test)\n",
    "        qt = t.ppf(0.95, max_surrounding_n-1) \n",
    "        halfwidth = max_surrounding_sd * qt * 1/np.sqrt(max_surrounding_n)\n",
    "\n",
    "        return max_surrounding_mean - halfwidth\n",
    "\n",
    "\n",
    "\n",
    "    def _CruiseSystem(self):\n",
    "        \"\"\" Helper that performs cruising \"\"\"\n",
    "\n",
    "        print(f\"Cruising: round {self._restarts}\\n\") \n",
    "\n",
    "        # get cruise combos in sorted order (furthest away from current max)\n",
    "        sorted_cruise_combos = self._sort_cruise_combos(self.best_combo)\n",
    "\n",
    "        # calculate warning threshold by getting max_surrounding_sd first\n",
    "        max_surrounding_mean, max_surrounding_sd = self._get_max_surrounding_mean_sd()\n",
    "\n",
    "        warning_threshold = self._cruise_warning_threshold(max_surrounding_mean, max_surrounding_sd, len(self._surrounding_vectors))\n",
    "\n",
    "        # check each cruise combo\n",
    "        for cruise_combo in sorted_cruise_combos:\n",
    "\n",
    "            # only search if it hasn't been cruised before (if has then is not an artifect of significance)\n",
    "            if not self.been_cruised[tuple(cruise_combo)]:\n",
    "                \n",
    "                self.been_cruised[tuple(cruise_combo)] = 2 # actually been cruised\n",
    "\n",
    "                # if above warning threshold, then stop cruise and restart guide\n",
    "                if self.result[tuple(cruise_combo)] >= warning_threshold:\n",
    "                   \n",
    "                    print(f\"Cruise suspended due to suspicious case\")\n",
    "                    \n",
    "                    return cruise_combo\n",
    "\n",
    "\n",
    "        # if reach here then all cruise indicies checked. can safely say end cruise\n",
    "        self._cruising = False\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def _get_core(self):\n",
    "        \"\"\" Helper to calculate core \"\"\"\n",
    "\n",
    "        self._core = [int(i/2) for i in self.n_items]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_surrounding_vectors(self, core):\n",
    "        \"\"\" Helper that gets the VECTORS that moves the core to the COORDINATES that form the 3^d object around it \"\"\"\n",
    "        ##ALGORITHM: how to generate all combinations of any dimensions given each dimension has different values\n",
    "        values = [-1, 0, 1]\n",
    "        new_surroundings = [[-1], [0], [1]]\n",
    "\n",
    "        for i in range(len(core) - 1):\n",
    "            old_surroundings = copy.deepcopy(new_surroundings)\n",
    "            new_surroundings = list()\n",
    "\n",
    "            for surrounding in old_surroundings:\n",
    "                for value in values:\n",
    "                    new_surroundings.append(\n",
    "                        [surrounding[i] if i < len(surrounding) else value for i in range(len(surrounding) + 1)])\n",
    "\n",
    "        return new_surroundings\n",
    "\n",
    "\n",
    "\n",
    "    def _get_surrounding_combos(self, core, surrounding_vectors):\n",
    "        \"\"\" Helper that uses surrounding VECTORS to find surrounding COORDINATES \"\"\"\n",
    "        \n",
    "        # Note this surrounding vector is not the same as the static local object generated by _get_surrounding_vectors\n",
    "\n",
    "        assert len(surrounding_vectors) > 0\n",
    "        assert len(surrounding_vectors[0]) == len(core)\n",
    "\n",
    "        # generate the surrounding combos (checking for whether they are still in the field) \n",
    "        surrounding_combos = list()\n",
    "        for i in range(len(surrounding_vectors)):\n",
    "            new_combo = self._new_combos(core, surrounding_vectors[i])\n",
    "            if new_combo is not False:\n",
    "                surrounding_combos.append(new_combo)\n",
    "\n",
    "        return surrounding_combos\n",
    "\n",
    "\n",
    "\n",
    "    def _new_combos(self, core, vector):\n",
    "        \"\"\" Helper that gets particular COORDINATE using a move in direction of VECTOR from particular CORE \"\"\"\n",
    "\n",
    "        assert len(core) == len(vector)\n",
    "\n",
    "        new_combo = list()\n",
    "        for i in range(len(vector)):\n",
    "            val = core[i] + vector[i]\n",
    "            if val >= self.n_items[i] or val < 0: # check whether combo is still in the field\n",
    "                return False\n",
    "            new_combo.append(val)\n",
    "\n",
    "        return new_combo\n",
    "\n",
    "\n",
    "\n",
    "    def _find_horizontal(self, surrounding_combos, core):\n",
    "        \"\"\" Helper that finds the treatment and nulls block from a 'Horizontal' vector move \"\"\"\n",
    "\n",
    "        treatment = list()\n",
    "        null = list()\n",
    "        direction = list()\n",
    "\n",
    "        for i in range(len(core)):\n",
    "\n",
    "            for move in [-1, 1]:\n",
    "                treatment_target = core[i] + move\n",
    "                null_target = core[i]\n",
    "\n",
    "                treatment_tmp = list()\n",
    "                null_tmp = list()\n",
    "\n",
    "                for vector in surrounding_combos:\n",
    "                    if vector[i] == treatment_target:\n",
    "                        treatment_tmp.append(vector)\n",
    "                    elif vector[i] == null_target:\n",
    "                        null_tmp.append(vector)\n",
    "\n",
    "                treatment.append(treatment_tmp)\n",
    "                null.append(null_tmp)\n",
    "                direction.append([move if j == i else 0 for j in range(len(core))])\n",
    "\n",
    "        return treatment, null, direction\n",
    "\n",
    "\n",
    "\n",
    "    def _pick_x(self, i, core):\n",
    "        \"\"\" Helper that picks all combinations of range(len(core)) for indexing when getting diagonal treatments \"\"\"\n",
    "\n",
    "        return list(combinations(list(range(len(core))), i))\n",
    "\n",
    "\n",
    "\n",
    "    def get_indices(self, core):\n",
    "        \"\"\" Helper that gets combinations of index to be used to find diagonal treatments: part of special algorithm \"\"\"\n",
    "\n",
    "        indices = list()\n",
    "        for i in range(len(core)):\n",
    "            for obj in self._pick_x(i, core):\n",
    "                indices.append(obj)\n",
    "\n",
    "        return indices\n",
    "\n",
    "\n",
    "\n",
    "    def _find_diagonal(self, core, indices):\n",
    "        \"\"\" Helper that finds the treatment and nulls block from a 'Diagonal' vector move (effectively interaction of all params) \"\"\"\n",
    "\n",
    "        treatment = list()\n",
    "        null = list()\n",
    "\n",
    "        diagonals = self._get_diagonals()\n",
    "\n",
    "        for diagonal in diagonals:\n",
    "            treatment.append(self._get_diagonal_treatment(core, diagonal, indices))\n",
    "\n",
    "            null.append(self._get_diagonal_null(core, diagonal))\n",
    "\n",
    "        return treatment, null, diagonals\n",
    "\n",
    "\n",
    "\n",
    "    def _get_diagonals(self):\n",
    "        \"\"\" Helper that finds all the diagonal vectors \"\"\"\n",
    "\n",
    "        return [obj for obj in self._surrounding_vectors if 0 not in obj]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_diagonal_treatment(self, core, diagonal, indices):\n",
    "        \"\"\" Helper that finds all diagonal treatments of this diagonal direction - any vector that has from 1 to d elements in same\n",
    "        direction diagonal, and all other vector positions 0 \"\"\"\n",
    "\n",
    "        treatment = self._get_surrounding_combos(core, self._get_diag_treatment_vectors(indices, diagonal))\n",
    "\n",
    "        return treatment\n",
    "\n",
    "\n",
    "\n",
    "    def _get_diag_treatment_vectors(self, indices, diagonal):\n",
    "        \"\"\" Helper that finds all vectors for diagonal treatments (orthogonal to direction or  0 vector) \"\"\"\n",
    "\n",
    "        diag_vectors = list()\n",
    "\n",
    "        for index in indices:\n",
    "            tmp = [0 for i in range(len(diagonal))]\n",
    "            for i in index:\n",
    "                tmp[i] = diagonal[i]\n",
    "            diag_vectors.append(tmp)\n",
    "\n",
    "        return diag_vectors\n",
    "\n",
    "\n",
    "\n",
    "    def _get_diagonal_null(self, core, diagonal):\n",
    "        \"\"\" Helper that finds all diagonal nulls of this diagonal direction - any vector that is orthogonal to the current direction \"\"\"\n",
    "\n",
    "        null = list()\n",
    "        for surrounding_vector in self._surrounding_vectors:\n",
    "            if np.dot(surrounding_vector, diagonal) == 0:\n",
    "                new_combo = self._new_combos(core, surrounding_vector)\n",
    "                if new_combo is not False:\n",
    "                    null.append(new_combo)\n",
    "\n",
    "        return null\n",
    "\n",
    "\n",
    "\n",
    "    def _get_blocks(self, core, surrounding_combos, indices):\n",
    "        \"\"\" Helper that gets all blocks' treatments and nulls (in respective lists) (both horizontal and diagonal) \"\"\"\n",
    "\n",
    "        treatment = list()\n",
    "        null = list()\n",
    "        direction = list()\n",
    "\n",
    "        hor_treatment, hor_null, hor_dir = self._find_horizontal(surrounding_combos, core)\n",
    "\n",
    "        diag_treatment, diag_null, vert_dir = self._find_diagonal(core, indices)\n",
    "\n",
    "        treatment.extend(hor_treatment)\n",
    "        treatment.extend(diag_treatment)\n",
    "\n",
    "        null.extend(hor_null)\n",
    "        null.extend(diag_null)\n",
    "\n",
    "        direction.extend(hor_dir)\n",
    "        direction.extend(vert_dir)\n",
    "\n",
    "        return treatment, null, direction\n",
    "\n",
    "\n",
    "\n",
    "    def _get_treat_or_null_tune_scores(self, treat_or_null):\n",
    "        \"\"\" Helper that returns as the relevant scores as a list to be used for t_test \"\"\"\n",
    "\n",
    "        treat_or_null_score = dict()\n",
    "\n",
    "        for combo in treat_or_null:\n",
    "            treat_or_null_score[tuple(combo)] = self.result[tuple(combo)]\n",
    "\n",
    "        return treat_or_null_score\n",
    "\n",
    "\n",
    "\n",
    "    def _dict_arg_max(self, dic):\n",
    "        \"\"\" Helper that finds key of maximum dict value \"\"\"\n",
    "        \n",
    "        max_val = -np.inf\n",
    "        for key in dic:\n",
    "            if dic[key] > max_val:\n",
    "                max_val = dic[key]\n",
    "                max_key = key\n",
    "\n",
    "        return max_key\n",
    "\n",
    "\n",
    "\n",
    "    def _xlnx(self, x):\n",
    "        \"\"\" Helper that returns x*ln(x), rounding up to next int \"\"\"\n",
    "        y = int(x*np.log(x))+1\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "    def _find_new_core(self, treatment, null, direction, core):\n",
    "        \"\"\" Helper that finds new cores - only those treatments with positive mean difference and p value < 0.05 \"\"\"\n",
    "\n",
    "        assert len(treatment) == len(null)\n",
    "        assert len(treatment) == len(direction)\n",
    "\n",
    "        new_cores = []\n",
    "\n",
    "        tmp_new_cores = list()\n",
    "        \n",
    "        for i in range(len(treatment)): \n",
    "            if len(treatment[i]) <= 1 or len(null[i]) <= 1:\n",
    "                continue\n",
    "\n",
    "            bool_inc = np.mean(list(self._get_treat_or_null_tune_scores(treatment[i]).values())) > np.mean(\n",
    "                list(self._get_treat_or_null_tune_scores(null[i]).values()))\n",
    "            \n",
    "            if bool_inc: # check if the treatment mean > null mean\n",
    "\n",
    "                p_val = stats.ttest_ind(list(self._get_treat_or_null_tune_scores(treatment[i]).values()),\n",
    "                                    list(self._get_treat_or_null_tune_scores(null[i]).values()),\n",
    "                                    equal_var=False).pvalue\n",
    "\n",
    "                if p_val < 0.05: # check if p value < 0.05\n",
    "                    \n",
    "                    # get the main combo of treatment = direction + core as a proposed new core\n",
    "                    proposed_new_core = tuple([direction[i][j] + core[j] for j in range(len(core))])\n",
    "\n",
    "                    # get the max combo of the treatment\n",
    "                    max_combo_of_treatment = self._dict_arg_max(self._get_treat_or_null_tune_scores(treatment[i])) \n",
    "\n",
    "                    # test if proposed new core is still on the grid\n",
    "                    add_dir = True\n",
    "                    for j in range(len(proposed_new_core)):\n",
    "                        if proposed_new_core[j] < 0 or proposed_new_core[j] >= self.n_items[j]:\n",
    "                            add_dir = False\n",
    "                            break\n",
    "                    \n",
    "                    # if proposed new core is on the grid, then put it in tmp_new_core along with its p value\n",
    "                    if add_dir:\n",
    "                        if not self.checked_core[ proposed_new_core ]:\n",
    "                            tmp_new_cores.append([proposed_new_core, p_val])\n",
    "\n",
    "                    # if not, put in the max core\n",
    "                    else:\n",
    "                        if not self.checked_core[ tuple(max_combo_of_treatment) ]:\n",
    "                            tmp_new_cores.append([tuple(max_combo_of_treatment), p_val])\n",
    "                        \n",
    "        # sort the tmp new cores list according to p values\n",
    "        tmp_new_cores.sort(key = lambda x:x[1])\n",
    "\n",
    "        # calculate how many new cores to accept according to the dimension of the grid (x = dim; accept x*ln(x))\n",
    "        n_accept = self._xlnx(len(core))\n",
    "        \n",
    "        for i in range(len(tmp_new_cores)):\n",
    "            if i >= n_accept:\n",
    "                break\n",
    "\n",
    "            new_cores.append(tmp_new_cores[i][0])\n",
    "            self.checked_core[ tmp_new_cores[i][0] ] = 1\n",
    "\n",
    "        return new_cores\n",
    "\n",
    "\n",
    "\n",
    "    def _get_new_cores(self, core):\n",
    "        \"\"\" Helper that gets new cores given old cores (performs the welch tests) \"\"\"\n",
    "\n",
    "        # if (should be rare) case where core has been a core before, then skip. For prevention of infinite loops\n",
    "        # 2 means actual checked core, 1 means appended to checked core list but not checked\n",
    "        if self.checked_core[tuple(core)] == 2:\n",
    "            return\n",
    "        else:\n",
    "            self.checked_core[tuple(core)] = 2 # actually been checked as a core\n",
    "            \n",
    "\n",
    "        # prepare data for welch test\n",
    "        surrounding_combos = self._get_surrounding_combos(core, self._surrounding_vectors)\n",
    "\n",
    "        indices = self.get_indices(core)\n",
    "\n",
    "        # put combos into treatments and nulls\n",
    "        treatment, null, direction = self._get_blocks(core, surrounding_combos, indices)\n",
    "\n",
    "        # actually tune the surrounding combos\n",
    "        for combo in surrounding_combos:\n",
    "            \n",
    "            if self.checked[tuple(combo)] == 0:\n",
    "                self._train_and_test_combo(combo)\n",
    "            else:\n",
    "                print(f'\\tAlready Trained and Tested combination {combo}')\n",
    "\n",
    "        # perform welch test and return surrounding combos that should be used as new core\n",
    "        new_cores = self._find_new_core(treatment, null, direction, core)\n",
    "\n",
    "        return new_cores  \n",
    "\n",
    "\n",
    "\n",
    "    def _GuidanceSystem(self, core):\n",
    "        \"\"\" Helper that performs guidance search \"\"\"\n",
    "\n",
    "        if self._restarts == 0:\n",
    "            print(\"Guidance: initial round \\n\")\n",
    "        else:\n",
    "            print(\"Guidance: round\", self._restarts, '\\n')\n",
    "\n",
    "        print('\\tround', self._restarts, 'iteration: ', 0, '\\n')\n",
    "\n",
    "        # first get a surrounding 3^d tuned\n",
    "        new_cores = self._get_new_cores(core)\n",
    "        self.been_cruised[tuple(core)] = 1 # represent don't need to be added as a to cruised - but not cruised, rather a core\n",
    "\n",
    "        round = 1\n",
    "        while new_cores: # while new cores are being added\n",
    "            print('\\tround', self._restarts, \"iteration: \", round, \"\\n\") \n",
    "            round += 1\n",
    "\n",
    "            old_new_cores = copy.deepcopy(new_cores)\n",
    "            new_cores = list()\n",
    "\n",
    "            # for each of the new cores, 'recursively' tune and grab new cores; but each Iteration doesn't end until all cores of current round has been checked\n",
    "            for new_core in old_new_cores:\n",
    "                \n",
    "                new_new_cores = self._get_new_cores(new_core)\n",
    "\n",
    "                if not new_new_cores:\n",
    "                    new_new_cores = []\n",
    "\n",
    "                self.been_cruised[tuple(core)] == 1\n",
    "                \n",
    "                for new_new_core in new_new_cores:\n",
    "                    if self.checked_core[tuple(new_new_core)] == 0:\n",
    "                        new_cores.append(new_new_core)\n",
    "                        self.checked_core[tuple(new_new_core)] = 1 # represent added to checked core - to prevent repeated added to core\n",
    "\n",
    "\n",
    "        # for current max, get 3^d block. if new max happens to be found, continue to do 3^d block until no new max is found\n",
    "        # just a cheap way to flesh out the max (the goal of YangZhou)\n",
    "        while self.been_best[tuple(self.best_combo)] == 0:\n",
    "\n",
    "            self.been_best[tuple(self.best_combo)] = 1 \n",
    "    \n",
    "            surrounding_combos = self._get_surrounding_combos(self.best_combo, self._surrounding_vectors)\n",
    "            for combo in surrounding_combos:\n",
    "                \n",
    "                if self.checked[tuple(combo)] == 0:\n",
    "                    self._train_and_test_combo(combo)\n",
    "                else:\n",
    "                    print(f'\\tAlready Trained and Tested combination {combo}')\n",
    "\n",
    "        # print information of this round \n",
    "\n",
    "        print('% Combos Checked Thus Far:', int(sum(self.checked.reshape((np.prod(self.n_items))))), 'out of', np.prod(self.n_items), 'which is', f'{np.mean(self.checked).round(8)*100}%')\n",
    "\n",
    "\n",
    "\n",
    "    def tune(self):\n",
    "        \"\"\" Begin tuning \"\"\"\n",
    "\n",
    "        if self.train_x is None or self.train_y is None or self.val_x is None or self.val_y is None or self.test_x is None or self.test_y is None:\n",
    "            print(\" Missing one of the datasets, please run .read_in_data() \")\n",
    "            return\n",
    "\n",
    "        if self.model is None:\n",
    "            print(\" Missing model, please run .read_in_model() \")\n",
    "            return\n",
    "\n",
    "        if self.tuning_result_saving_address is None:\n",
    "            print(\"Missing tuning result csv saving address, please run ._save_tuning_result() first\")\n",
    "\n",
    "\n",
    "\n",
    "        print(\"BEGIN TUNING\\n\\n\") \n",
    "        \n",
    "        # FIRST: get all cruise combinations as well as core, and tune all these\n",
    "        self._get_core()\n",
    "        self._get_cruise_combinations() \n",
    "\n",
    "        first_round_combinations = copy.deepcopy(self._cruise_combinations)\n",
    "        first_round_combinations.append(self._core) \n",
    "\n",
    "        random.seed(self._seed)\n",
    "        random.shuffle(first_round_combinations)\n",
    "\n",
    "        print(\"STAGE ZERO: Tune all Cruise combinations\\n\\n\")\n",
    "        for combo in first_round_combinations:\n",
    "            \n",
    "            if not self.checked[tuple(combo)]:\n",
    "                \n",
    "                self._train_and_test_combo(combo)\n",
    "            \n",
    "            else:\n",
    "                print(f'\\tAlready Trained and Tested combination {combo}')\n",
    "        \n",
    "\n",
    "        # SECOND: from the core combo, begin guidance system\n",
    "        self._surrounding_vectors = self._get_surrounding_vectors(self._core)\n",
    "\n",
    "        print('\\n')\n",
    "        print(\"STAGE ONE: Begin initial Guidance system\\n\\n\")\n",
    "\n",
    "        self._restarts = 0\n",
    "        self._GuidanceSystem(self._core) # Initial Round of Guidance\n",
    "        self._restarts += 1\n",
    "\n",
    "        # THIRD: Recursively Cruise and restart Guide if find a combo that is within halfwidth of max\n",
    "        print(\"STAGE TWO: Begin Cruise system\\n\\n\")\n",
    "        self._cruising = True\n",
    "        while self._cruising:\n",
    "            suspicious_case_combo = self._CruiseSystem()\n",
    "\n",
    "            if self._cruising:\n",
    "                self._GuidanceSystem(tuple(suspicious_case_combo))\n",
    "                self._restarts += 1\n",
    "\n",
    "        # FINALLY: Final extensive guidance search around maxes.\n",
    "        print(\"FINAL STAGE: Begin final Guidance system\\n\\n\")\n",
    "        old_best_score = copy.deepcopy(self.best_score)\n",
    "        self._restarts = 'FINAL'\n",
    "\n",
    "        self._GuidanceSystem(self.best_combo)\n",
    "\n",
    "        while(self.best_score-old_best_score > 0):\n",
    "            old_best_score = copy.deepcopy(self.best_score)\n",
    "            self._GuidanceSystem(self.best_combo)\n",
    "\n",
    "\n",
    "\n",
    "        # Display final information\n",
    "        print(\"TUNING FINISHED\\n\")\n",
    "\n",
    "        print('Max Score: \\n', self.best_score)\n",
    "        print('Max Combo: \\n', self.best_combo)\n",
    "\n",
    "        print('% Combos Checked:', int(sum(self.checked.reshape((np.prod(self.n_items))))), 'out of', np.prod(self.n_items), 'which is', f'{np.mean(self.checked).round(8)*100}%')\n",
    "    \n",
    "\n",
    "\n",
    "    def _train_and_test_combo(self, combo):\n",
    "        \"\"\" Helper to train and test each combination as part of tune() \"\"\"\n",
    "\n",
    "        combo = tuple(combo)\n",
    "        \n",
    "        params = {self.hyperparameters[i]:self.parameter_choices[self.hyperparameters[i]][combo[i]] for i in range(len(self.hyperparameters))}\n",
    "\n",
    "        # initialise object\n",
    "        clf = self.model(**params)\n",
    "\n",
    "        # get time and fit\n",
    "        start = time.time()\n",
    "        clf.fit(self.train_x, self.train_y)\n",
    "        end = time.time()\n",
    "\n",
    "        # get predicted labels/values for three datasets\n",
    "        train_pred = clf.predict(self.train_x)\n",
    "        val_pred = clf.predict(self.val_x)\n",
    "        test_pred = clf.predict(self.test_x)\n",
    "\n",
    "        # get scores and time used\n",
    "        time_used = end-start\n",
    "\n",
    "        # build output dictionary and save result\n",
    "        df_building_dict = params\n",
    "\n",
    "        if self.clf_type == 'Regression':\n",
    "            train_score = r2_score(self.train_y, train_pred)\n",
    "            val_score = r2_score(self.val_y, val_pred)\n",
    "            test_score = r2_score(self.test_y, test_pred)\n",
    "\n",
    "            train_rmse = np.sqrt(mean_squared_error(self.train_y, train_pred))\n",
    "            val_rmse = np.sqrt(mean_squared_error(self.val_y, val_pred))\n",
    "            test_rmse = np.sqrt(mean_squared_error(self.test_y, test_pred))\n",
    "\n",
    "            train_mape = mean_absolute_percentage_error(self.train_y, train_pred)\n",
    "            val_mape = mean_absolute_percentage_error(self.val_y, val_pred)\n",
    "            test_mape = mean_absolute_percentage_error(self.test_y, test_pred)\n",
    "\n",
    "            df_building_dict['Train r2'] = [np.round(train_score, 4)]\n",
    "            df_building_dict['Val r2'] = [np.round(val_score, 4)]\n",
    "            df_building_dict['Test r2'] = [np.round(test_score, 4)]\n",
    "            df_building_dict['Train RMSE'] = [np.round(train_rmse, 4)]\n",
    "            df_building_dict['Val RMSE'] = [np.round(val_rmse, 4)]\n",
    "            df_building_dict['Test RMSE'] = [np.round(test_rmse, 4)]\n",
    "            df_building_dict['Train MAPE'] = [np.round(train_mape, 4)]\n",
    "            df_building_dict['Val MAPE'] = [np.round(val_mape, 4)]\n",
    "            df_building_dict['Test MAPE'] = [np.round(test_mape, 4)]\n",
    "            df_building_dict['Time'] = [np.round(time_used, 2)]\n",
    "\n",
    "        \n",
    "        elif self.clf_type == 'Classification':\n",
    "            train_score = clf.score(self.train_y, train_pred)\n",
    "            val_score = clf.score(self.val_y, val_pred)\n",
    "            test_score = clf.score(self.test_y, test_pred)\n",
    "\n",
    "            train_bal_accu = balanced_accuracy_score(self.train_y, train_pred)\n",
    "            val_bal_accu = balanced_accuracy_score(self.val_y, val_pred)\n",
    "            test_bal_accu = balanced_accuracy_score(self.test_y, test_pred)\n",
    "\n",
    "            train_f1 = f1_score(self.train_y, train_pred, average='weighted')\n",
    "            val_f1 = f1_score(self.val_y, val_pred, average='weighted')\n",
    "            test_f1 = f1_score(self.test_y, test_pred, average='weighted')\n",
    "\n",
    "            train_precision = precision_score(self.train_y, train_pred, average='weighted')\n",
    "            val_precision = precision_score(self.val_y, val_pred, average='weighted')\n",
    "            test_precision = precision_score(self.test_y, test_pred, average='weighted')\n",
    "        \n",
    "            train_recall = recall_score(self.train_y, train_pred, average='weighted')\n",
    "            val_recall = recall_score(self.val_y, val_pred, average='weighted')\n",
    "            test_recall = recall_score(self.test_y, test_pred, average='weighted')\n",
    "\n",
    "            df_building_dict['Train accu'] = [np.round(train_score, 4)]\n",
    "            df_building_dict['Val accu'] = [np.round(val_score, 4)]\n",
    "            df_building_dict['Test accu'] = [np.round(test_score, 4)]\n",
    "            df_building_dict['Train balanced_accuracy'] = [np.round(train_bal_accu, 4)]\n",
    "            df_building_dict['Val balanced_accuracy'] = [np.round(val_bal_accu, 4)]\n",
    "            df_building_dict['Test balanced_accuracy'] = [np.round(test_bal_accu, 4)]\n",
    "            df_building_dict['Train f1'] = [np.round(train_f1, 4)]\n",
    "            df_building_dict['Val f1'] = [np.round(val_f1, 4)]\n",
    "            df_building_dict['Test f1'] = [np.round(test_f1, 4)]\n",
    "            df_building_dict['Train precision'] = [np.round(train_precision, 4)]\n",
    "            df_building_dict['Val precision'] = [np.round(val_precision, 4)]\n",
    "            df_building_dict['Test precision'] = [np.round(test_precision, 4)]\n",
    "            df_building_dict['Train recall'] = [np.round(train_recall, 4)]\n",
    "            df_building_dict['Val recall'] = [np.round(val_recall, 4)]\n",
    "            df_building_dict['Test recall'] = [np.round(test_recall, 4)]\n",
    "            df_building_dict['Time'] = [np.round(time_used, 2)]\n",
    "\n",
    "        tmp = pd.DataFrame(df_building_dict)\n",
    "\n",
    "        self.tuning_result = self.tuning_result.append(tmp)\n",
    "        self._save_tuning_result()\n",
    "\n",
    "        # update best score stats\n",
    "        if val_score > self.best_score: \n",
    "            self.best_score = val_score\n",
    "            self.best_clf = clf\n",
    "            self.best_combo = combo\n",
    "\n",
    "        # update internal governing DataFrames\n",
    "        self.checked[combo] = 1\n",
    "        self.result[combo] = val_score\n",
    "\n",
    "        print(f'''\\tTrained and Tested a Combo, taking {np.round(time_used, 2)} seconds\n",
    "            Current best combo: {self.best_combo} with val score {self.best_score}''')\n",
    "\n",
    "\n",
    "\n",
    "    def _save_tuning_result(self):\n",
    "        \"\"\" Helper to export tuning result csv \"\"\"\n",
    "\n",
    "        tuning_result_saving_address_split = self.tuning_result_saving_address.split('.csv')[0]\n",
    "\n",
    "        self.tuning_result.to_csv(f'{self.tuning_result_saving_address_split}.csv', index=False)\n",
    "\n",
    "    \n",
    "\n",
    "    def view_best_combo_and_score(self):\n",
    "        \"\"\" View best combination and its validation score \"\"\"\n",
    "        \n",
    "        print(f'(Current) Best combo: {self.best_combo} with val score {self.best_score}')\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_tuning_result_df(self, address): \n",
    "        \"\"\" Read in tuning result csv and read data into checked and result arrays \"\"\"\n",
    "\n",
    "        if self.parameter_choices is None:\n",
    "            print(\"Missing parameter_choices to build parameter_value_map_index, please run set_hyperparameters() first\")\n",
    "\n",
    "        if self.clf_type is None:\n",
    "            print('Missing clf_type. Please run .read_in_model() first.')\n",
    "\n",
    "        self.tuning_result = pd.read_csv(address)\n",
    "        print(f\"Successfully read in tuning result of {len(self.tuning_result)} rows\")\n",
    "\n",
    "        self._create_parameter_value_map_index()\n",
    "\n",
    "        # read DataFrame data into internal governing DataFrames of YangZhou\n",
    "        for row in self.tuning_result.iterrows():\n",
    "    \n",
    "            combo = tuple([self._parameter_value_map_index[hyperparam][row[1][hyperparam]] for hyperparam in self.hyperparameters])\n",
    "            \n",
    "            self.checked[combo] = 1\n",
    "            \n",
    "            if self.clf_type == 'Regression':\n",
    "                self.result[combo] = row[1]['Val r2']\n",
    "            elif self.clf_type == 'Classification':\n",
    "                self.result[combo] = row[1]['Val accu']\n",
    "        \n",
    "            # update best score stats\n",
    "            if self.result[combo] > self.best_score: \n",
    "                self.best_score = self.result[combo]\n",
    "                self.best_clf = None\n",
    "                print(f\"As new Best Combo {combo} is read in, best_clf is set to None\")\n",
    "                self.best_combo = combo\n",
    "\n",
    "\n",
    "    \n",
    "    def _create_parameter_value_map_index(self):\n",
    "        \"\"\" Helper to create parameter-value index map \"\"\"\n",
    "\n",
    "        self._parameter_value_map_index = dict()\n",
    "        for key in self.parameter_choices.keys():\n",
    "            tmp = dict()\n",
    "            for i in range(len(self.parameter_choices[key])):\n",
    "                tmp[self.parameter_choices[key][i]] = i\n",
    "            self._parameter_value_map_index[key] = tmp\n",
    "\n",
    "\n",
    "    \n",
    "    def set_tuning_result_saving_address(self, address):\n",
    "        \"\"\" Read in where to save tuning object \"\"\"\n",
    "\n",
    "        self.tuning_result_saving_address = address\n",
    "        print('Successfully set tuning output address')\n",
    "\n",
    "\n",
    "\n",
    "    def _set_object_saving_address(self, address):\n",
    "        \"\"\" Read in where to save the YangZhou object \"\"\"\n",
    "\n",
    "        self.object_saving_address = address\n",
    "        print('Successfully set object output address')\n",
    "\n",
    "\n",
    "\n",
    "    def export_yangzhou(self, address):\n",
    "        \"\"\" Export yangzhou object \"\"\"\n",
    "\n",
    "        self._set_object_saving_address(address)\n",
    "\n",
    "        # copy object and set big objects to None\n",
    "        object_save = copy.deepcopy(self)\n",
    "        \n",
    "        object_save.train_x = None\n",
    "        object_save.train_y = None\n",
    "        object_save.val_x = None\n",
    "        object_save.val_y = None\n",
    "        object_save.test_x = None\n",
    "        object_save.test_y = None\n",
    "\n",
    "        # Export\n",
    "        object_saving_address_split = self.object_saving_address.split('.pickle')[0]\n",
    "\n",
    "        with open(f'{object_saving_address_split}.pickle', 'wb') as f:\n",
    "            pickle.dump(object_save, f)\n",
    "\n",
    "        print(f'Successfully exported YangZhou object as {self.object_saving_address}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
