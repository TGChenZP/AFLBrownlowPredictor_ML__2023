{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3), (1, 2), (3, 2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [1, 3, 2]\n",
    "list(combinations(lst, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must import NingXiang for cruise\n",
    "## and then use this for generating features\n",
    "\n",
    "# deal with 0 features?? features are 主力？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first generate all combinations\n",
    "##sort internal lists\n",
    "# then, store them into dicts by length\n",
    "\n",
    "# when need to change layer, try add 1 and subtract 1 - all combos\n",
    "\n",
    "\n",
    "\n",
    "# core: NingXiang's middle; and min, and max. 3 places begin\n",
    "# cruise: pick middle ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as s\n",
    "import copy\n",
    "import time\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import t\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuDong:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialise class \"\"\"\n",
    "        self._initialise_objects()\n",
    "\n",
    "        print('PuDong Initialised')\n",
    "\n",
    "\n",
    "\n",
    "    def _initialise_objects(self):\n",
    "        \"\"\" Helper to initialise objects \"\"\"\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.val_x = None\n",
    "        self.val_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "        self.tuning_result = None\n",
    "        self.model = None\n",
    "        self.parameter_choices = None\n",
    "        self.hyperparameters = None\n",
    "        self.feature_n_ningxiang_score_dict = None\n",
    "        self.non_tuneable_parameter_choices = None\n",
    "        self.checked = None\n",
    "        self.result = None\n",
    "        self.checked_core = None\n",
    "        self.been_best = None\n",
    "        self.been_cruised = None\n",
    "        self.tuning_result_saving_address = None\n",
    "        self.object_saving_address = None\n",
    "        self._parameter_value_map_index = None\n",
    "        self._seed = 19260817\n",
    "        self.best_score = -np.inf\n",
    "        self.best_combo = None\n",
    "        self.best_clf = None\n",
    "        self.clf_type = None\n",
    "        self.n_items = None\n",
    "        self._core = None\n",
    "        self._cruise_indices = None\n",
    "        self._cruise_indices_values = None\n",
    "        self._cruise_combinations = None\n",
    "        self._restarts = 0\n",
    "        self._cruising = True\n",
    "        self._surrounding_vectors = None\n",
    "        self._total_combos = None\n",
    "        self._tune_features = False\n",
    "\n",
    "        self.regression_extra_output_columns = ['Train r2', 'Val r2', 'Test r2', \n",
    "            'Train RMSE', 'Val RMSE', 'Test RMSE', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Time']\n",
    "        self.classification_extra_output_columns = ['Train accu', 'Val accu', 'Test accu', \n",
    "            'Train balanced_accu', 'Val balanced_accu', 'Test balanced_accu', 'Train f1', 'Val f1', 'Test f1', \n",
    "            'Train precision', 'Val precision', 'Test precision', 'Train recall', 'Val recall', 'Test recall', 'Time']\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_data(self, train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "        \"\"\" Reads in train validate test data for tuning \"\"\"\n",
    "\n",
    "        self.train_x = train_x\n",
    "        print(\"Read in Train X data\")\n",
    "\n",
    "        self.train_y = train_y\n",
    "        print(\"Read in Train x data\")\n",
    "\n",
    "        self.val_x = val_x\n",
    "        print(\"Read in Val X data\")\n",
    "\n",
    "        self.val_y = val_y\n",
    "        print(\"Read in Val y data\")\n",
    "\n",
    "        self.test_x = test_x\n",
    "        print(\"Read in Test X data\")\n",
    "\n",
    "        self.test_y = test_y\n",
    "        print(\"Read in Test y data\")\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_model(self, model, type):\n",
    "        \"\"\" Reads in underlying model object for tuning, and also read in what type of model it is \"\"\"\n",
    "\n",
    "        assert type == 'Classification' or type == 'Regression' # check\n",
    "\n",
    "        # record\n",
    "        self.model = model\n",
    "        self.clf_type = type \n",
    "\n",
    "        print(f'Successfully read in model {self.model}, which is a {self.clf_type} model')\n",
    "\n",
    "\n",
    "\n",
    "    def set_hyperparameters(self, parameter_choices):\n",
    "        \"\"\" Input hyperparameter choices \"\"\"\n",
    "\n",
    "        self.parameter_choices = parameter_choices\n",
    "        self._sort_hyperparameter_choices()\n",
    "\n",
    "        self.hyperparameters = list(parameter_choices.keys())\n",
    "\n",
    "        # automatically calculate how many different values in each hyperparameter\n",
    "        self.n_items = [len(parameter_choices[key]) for key in self.hyperparameters]\n",
    "        self.num_hyperparameters = {hyperparameter:len(parameter_choices[hyperparameter]) for hyperparameter in self.hyperparameters}\n",
    "        self._total_combos = np.prod(self.n_items)\n",
    "\n",
    "        # automatically setup checked and result arrays and tuning result dataframe\n",
    "        self._get_checked_and_result_array()\n",
    "        self._setup_tuning_result_df()\n",
    "\n",
    "        print(\"Successfully recorded hyperparameter choices\")\n",
    "\n",
    "\n",
    "    \n",
    "    def _sort_hyperparameter_choices(self):\n",
    "        \"\"\" Helper to ensure all hyperparameter choice values are in order from lowest to highest \"\"\"\n",
    "\n",
    "        for key in self.parameter_choices:\n",
    "            tmp = copy.deepcopy(list(self.parameter_choices[key]))\n",
    "            tmp.sort()\n",
    "            self.parameter_choices[key] = tuple(tmp)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_checked_and_result_array(self):\n",
    "        \"\"\" Helper to set up checked and result array \"\"\"\n",
    "\n",
    "        self.checked = np.zeros(shape=self.n_items)\n",
    "        self.result = np.zeros(shape=self.n_items)\n",
    "        self.checked_core = np.zeros(shape=self.n_items)\n",
    "        self.been_best = np.zeros(shape=self.n_items) # strictly for last part of Guidance Algorithm\n",
    "        self.been_cruised = np.zeros(shape=self.n_items)\n",
    "\n",
    "\n",
    "\n",
    "    def _setup_tuning_result_df(self):\n",
    "        \"\"\" Helper to set up tuning result dataframe \"\"\"\n",
    "\n",
    "        tune_result_columns = copy.deepcopy(self.hyperparameters)\n",
    "\n",
    "        # Different set of metric columns for different types of models\n",
    "        if self.clf_type == 'Classification':\n",
    "            tune_result_columns.extend(self.classification_extra_output_columns)\n",
    "        elif self.clf_type == 'Regression':\n",
    "            tune_result_columns.extend(self.regression_extra_output_columns)\n",
    "\n",
    "        self.tuning_result = pd.DataFrame({col:list() for col in tune_result_columns})\n",
    "\n",
    "\n",
    "\n",
    "    def set_non_tuneable_hyperparameters(self, non_tuneable_hyperparameter_choice):\n",
    "        \"\"\" Input Non tuneable hyperparameter choice \"\"\"\n",
    "\n",
    "        if type(non_tuneable_hyperparameter_choice) is not dict:\n",
    "            print('non_tuneable_hyeprparameters_choice must be dict, please try again')\n",
    "            return\n",
    "        \n",
    "        for nthp in non_tuneable_hyperparameter_choice:\n",
    "            if type(non_tuneable_hyperparameter_choice[nthp]) in (set, list, tuple, dict):\n",
    "                print('non_tuneable_hyperparameters_choice must not be of array-like type')\n",
    "                return\n",
    "\n",
    "        self.non_tuneable_parameter_choices = non_tuneable_hyperparameter_choice\n",
    "\n",
    "        print(\"Successfully recorded non_tuneable_hyperparameter choices\")\n",
    "\n",
    "\n",
    "\n",
    "    def set_features(self, ningxiang_output):\n",
    "        \"\"\" Input features \"\"\"\n",
    "\n",
    "        if type(ningxiang_output) is not dict:\n",
    "            print(\"Please ensure NingXiang output is a dict\")\n",
    "            return\n",
    "        \n",
    "        if not self.combos:\n",
    "            print(\"Missing hyperparameter choices, please run .set_hyperparameters() first\")\n",
    "            return\n",
    "        \n",
    "        # sort ningxiang just for safety, and store up\n",
    "        ningxiang_output_sorted = self._sort_features(ningxiang_output)\n",
    "        self.feature_n_ningxiang_score_dict = ningxiang_output_sorted\n",
    "\n",
    "        # activate this switch\n",
    "        self._tune_features = True\n",
    "\n",
    "        # update previous internal structures based on first set of hyperparameter choices\n",
    "        ##here used numbers instead of tuples as the values in parameter_choices; thus need another mapping to get map back to the features\n",
    "        self.parameter_choices['features'] = tuple([i for i in range(len(ningxiang_output_sorted))])\n",
    "        self.feature_combo_n_index_map = {i: ningxiang_output_sorted.keys()[i] for i in range(len(ningxiang_output_sorted))}\n",
    "\n",
    "        self.hyperparameters = list(self.parameter_choices.keys())\n",
    "\n",
    "        # automatically calculate how many different values in each hyperparameter\n",
    "        self.n_items = [len(self.parameter_choices[key]) for key in self.hyperparameters]\n",
    "        self._total_combos = np.prod(self.n_items)\n",
    "\n",
    "        # automatically calculate all combinations and setup checked and result arrays and tuning result dataframe\n",
    "        self._get_combinations()\n",
    "        self._get_checked_and_result_array()\n",
    "        self._setup_tuning_result_df()\n",
    "\n",
    "        print(\"Successfully recorded tuneable feature combination choices and updated relevant internal structures\")\n",
    "\n",
    "\n",
    "    \n",
    "    def _sort_features(self, ningxiang_output):\n",
    "        \"\"\" Helper for sorting features based on NingXiang values (input dict output dict) \"\"\"\n",
    "\n",
    "        ningxiang_output_list = [(key, ningxiang_output[key]) for key in ningxiang_output]\n",
    "\n",
    "        ningxiang_output_list.sort(key = lambda x:x[1])\n",
    "\n",
    "        ningxiang_output_sorted = {x[0]:x[1] for x in ningxiang_output_list}\n",
    "\n",
    "        return ningxiang_output_sorted\n",
    "\n",
    "\n",
    "\n",
    "    def _get_core(self):\n",
    "        \"\"\" Helper to calculate core \"\"\"\n",
    "        self._core = [int(i/2) for i in self.n_items]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_combinations(self):\n",
    "        \"\"\" Helper to cruise combinations \"\"\"\n",
    "\n",
    "        self._get_cruise_indices_values()\n",
    "        self._generate_cruise_combinations() # first get cruise indicies, then use indicies to get combinations\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_indices_values(self):\n",
    "        \"\"\" Helper to get cruise indices values of each dimension which serves as building blocks for cruise combinations \"\"\"\n",
    "\n",
    "        self._cruise_indices = dict()\n",
    "        for hyperparameter in self.hyperparameters:\n",
    "            self._cruise_indices[hyperparameter] = self._get_cruise_indices_1d(d_val = self.num_hyperparameters[hyperparameter], max_jump = 5)\n",
    "\n",
    "        self._cruise_indices_values = list(self._cruise_indices.values())\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_indices_1d(self, d_val, max_jump = 5): \n",
    "        \"\"\" Helper that returns the appropriate cruise indices based on the number of values in dimension. Second argument controls maximum split size, defaulted to 5 \"\"\"\n",
    "\n",
    "        assert type(d_val) is int and type(max_jump) is int, \"Error: type of input(s) is not int\"\n",
    "        assert max_jump >= 1, \"Error: max_jump must be >= 1\"\n",
    "\n",
    "        gap = d_val - 1\n",
    "        split = ((gap-1)//max_jump)\n",
    "\n",
    "        jump = self._find_gaps(split, gap)\n",
    "\n",
    "        cruise_indices_1d = self._find_cruise_indices_1d(jump)\n",
    "\n",
    "        return cruise_indices_1d\n",
    "\n",
    "\n",
    "\n",
    "    def _find_gaps(self, split, gap):\n",
    "        \"\"\" Helper that finds the size of jumps between each element of the final cruise indices, as evenly split as possible with jump size <= 5 \"\"\"\n",
    "\n",
    "        if split > 0:\n",
    "            jump = [gap//(split+1) for i in range(split+1)]\n",
    "            diff = gap - sum(jump)\n",
    "            if diff:\n",
    "                for i in range(diff):\n",
    "                    jump[i] += 1\n",
    "        else:\n",
    "            jump = [gap]\n",
    "\n",
    "        return jump\n",
    "\n",
    "\n",
    "\n",
    "    def _find_cruise_indices_1d(self, jump):\n",
    "        \"\"\" Helper that finds the actual cruise_indices based on gaps \"\"\"\n",
    "\n",
    "        cruise_indices_1d = [0]\n",
    "        for i in range(len(jump)):\n",
    "            cruise_indices_1d.append(sum(jump[:i+1]))\n",
    "\n",
    "        if cruise_indices_1d == [0, 0]:\n",
    "            cruise_indices_1d = [0]\n",
    "            \n",
    "        return cruise_indices_1d\n",
    "\n",
    "\n",
    "\n",
    "    def _generate_cruise_combinations(self):\n",
    "        \"\"\" Helper that generates the actual cruise combinations based on cruise indicies \"\"\"\n",
    "        ##ALGORITHM: how to generate all combinations of any dimensions given each dimension has different values\n",
    "        self._cruise_combinations = [[]]\n",
    "        for i in range(len(self._cruise_indices_values)):\n",
    "\n",
    "            tmp = copy.deepcopy(self._cruise_combinations)\n",
    "            self._cruise_combinations = list()\n",
    "\n",
    "            for x in tmp:\n",
    "\n",
    "                for k in self._cruise_indices_values[i]:\n",
    "                    y = copy.deepcopy(x)\n",
    "                    \n",
    "                    y.append(k)\n",
    "\n",
    "                    self._cruise_combinations.append(y)\n",
    "\n",
    "\n",
    "\n",
    "    def _sort_cruise_combos(self, max_combo):\n",
    "        \"\"\" sort the cruise combos based on Euclidean distance from current max\"\"\"\n",
    "\n",
    "        edist = list(cdist([max_combo], self._cruise_combinations).flatten())\n",
    "        ordered_cruise_combos = [(self._cruise_combinations[i], edist[i]) for i in range(len(self._cruise_combinations))]\n",
    "\n",
    "        ordered_cruise_combos.sort(reverse=True, key=lambda x: x[1])\n",
    "\n",
    "        sorted_cruise_combos = [ordered_cruise_combos[i][0] for i in range(len(ordered_cruise_combos))]\n",
    "\n",
    "        return sorted_cruise_combos\n",
    "\n",
    "    \n",
    "\n",
    "    def _get_max_surrounding_mean_sd(self):\n",
    "        \"\"\" Helper to get the surrounding mean and sd given the current maximum \"\"\"\n",
    "\n",
    "        best_combo_surrounding_combos = self._get_surrounding_step_combos(self.best_combo)\n",
    "        best_combo_surrounding_scores = [self.best_score]\n",
    "        for combo in best_combo_surrounding_combos:\n",
    "            best_combo_surrounding_scores.append(self.result[tuple(combo)])\n",
    "\n",
    "        max_surrounding_mean = s.mean(best_combo_surrounding_scores)\n",
    "        max_surrounding_sd = s.stdev(best_combo_surrounding_scores)\n",
    "\n",
    "        return max_surrounding_mean, max_surrounding_sd\n",
    "\n",
    "\n",
    "\n",
    "    def _cruise_warning_threshold(self, max_surrounding_mean, max_surrounding_sd, max_surrounding_n):\n",
    "        \"\"\" Helper that gets the warning threshold by (mean of best_combo surrounds - halfwidth) \"\"\"\n",
    "\n",
    "        # use 0.95 (one sided test)\n",
    "        qt = t.ppf(0.95, max_surrounding_n-1) \n",
    "        halfwidth = max_surrounding_sd * qt * 1/np.sqrt(max_surrounding_n)\n",
    "\n",
    "        return max_surrounding_mean - halfwidth\n",
    "\n",
    "\n",
    "\n",
    "    def _CruiseSystem(self):\n",
    "        \"\"\" Helper that performs cruising \"\"\"\n",
    "\n",
    "        print(f\"Cruising: round {self._restarts}\\n\") \n",
    "\n",
    "        # get cruise combos in sorted order (furthest away from current max)\n",
    "        sorted_cruise_combos = self._sort_cruise_combos(self.best_combo)\n",
    "\n",
    "        # calculate warning threshold by getting max_surrounding_sd first\n",
    "        max_surrounding_mean, max_surrounding_sd = self._get_max_surrounding_mean_sd()\n",
    "\n",
    "        warning_threshold = self._cruise_warning_threshold(max_surrounding_mean, max_surrounding_sd, len(self._surrounding_vectors))\n",
    "\n",
    "        # check each cruise combo\n",
    "        for cruise_combo in sorted_cruise_combos:\n",
    "\n",
    "            # only search if it hasn't been cruised before (if has then is not an artifect of significance)\n",
    "            if not self.been_cruised[tuple(cruise_combo)]:\n",
    "                \n",
    "                self.been_cruised[tuple(cruise_combo)] = 2 # actually been cruised\n",
    "\n",
    "                # if above warning threshold, then stop cruise and restart guide\n",
    "                if self.result[tuple(cruise_combo)] >= warning_threshold:\n",
    "                   \n",
    "                    print(f\"Cruise suspended due to suspicious case\")\n",
    "                    \n",
    "                    return cruise_combo\n",
    "\n",
    "\n",
    "        # if reach here then all cruise indicies checked. can safely say end cruise\n",
    "        self._cruising = False\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def _get_core(self):\n",
    "        \"\"\" Helper to calculate core \"\"\"\n",
    "\n",
    "        self._core = [int(i/2) for i in self.n_items]\n",
    "\n",
    "\n",
    "\n",
    "    def _new_combos(self, core, vector):\n",
    "        \"\"\" Helper that gets particular COORDINATE using a move in direction of VECTOR from particular CORE \"\"\"\n",
    "\n",
    "        assert len(core) == len(vector)\n",
    "\n",
    "        new_combo = list()\n",
    "        for i in range(len(vector)):\n",
    "            val = core[i] + vector[i]\n",
    "            if val >= self.n_items[i] or val < 0: # check whether combo is still in the field\n",
    "                return False\n",
    "            new_combo.append(val)\n",
    "\n",
    "        return new_combo\n",
    "\n",
    "\n",
    "\n",
    "    def _xlnx(self, x):\n",
    "        \"\"\" Helper that returns x*ln(x), rounding up to next int \"\"\"\n",
    "        y = int(x*np.log(x))+1\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "    def _find_new_core(self, surrounding_combos, core):\n",
    "        \"\"\" Helper that finds new cores - only those candidates with difference between core and treatment < 0.005 \"\"\"\n",
    "\n",
    "        new_cores = []\n",
    "        tmp_new_cores = list()\n",
    "        \n",
    "        for i in range(len(surrounding_combos)): \n",
    "\n",
    "            diff = self.result[tuple(core)] - self.result[tuple(surrounding_combos[i])]\n",
    "\n",
    "            if diff <= 0.005:\n",
    "                if self.checked_core[ tuple(surrounding_combos[i]) ] == 0:\n",
    "                    tmp_new_cores.append([tuple(surrounding_combos[i]), diff])\n",
    "                        \n",
    "        # # sort the tmp new cores list according to p values\n",
    "        # tmp_new_cores.sort(key = lambda x:x[1])\n",
    "\n",
    "        # # calculate how many new cores to accept according to the dimension of the grid (x = dim; accept x*ln(x))\n",
    "        # n_accept = self._xlnx(len(core))\n",
    "        \n",
    "        for i in range(len(tmp_new_cores)):\n",
    "            # if i >= n_accept:\n",
    "            #     break\n",
    "\n",
    "            new_cores.append(tmp_new_cores[i][0])\n",
    "            self.checked_core[ tmp_new_cores[i][0] ] = 1\n",
    "\n",
    "        return new_cores\n",
    "\n",
    "\n",
    "\n",
    "    def _get_surrounding_step_vectors(self, core):\n",
    "        \"\"\" find all horizontal steps \"\"\"\n",
    "\n",
    "        all_steps = list()\n",
    "\n",
    "        for i in range(len(core)):\n",
    "            for val in [-1, 1]:\n",
    "                tmp = [0 for i in range(len(core))]\n",
    "                tmp[i] = val\n",
    "        \n",
    "                all_steps.append(tmp)\n",
    "        \n",
    "        return all_steps\n",
    "    \n",
    "\n",
    "\n",
    "    def _get_surrounding_step_combos(self, core):\n",
    "        \"\"\" find all vectors that are one horizontal steps away from core \"\"\"\n",
    "\n",
    "        surrounding_combos = list()\n",
    "        for step in self._surrounding_vectors:\n",
    "\n",
    "            add = 1\n",
    "            candidate_surrounding_combo = list()\n",
    "\n",
    "            for i in range(len(core)):\n",
    "                new_index = core[i]+step[i]\n",
    "                if new_index < 0 or new_index >= self.n_items[i]:\n",
    "                    add = 0\n",
    "                    break\n",
    "                else:\n",
    "                    candidate_surrounding_combo.append(new_index)\n",
    "\n",
    "            if add:    \n",
    "                surrounding_combos.append(candidate_surrounding_combo)\n",
    "\n",
    "        return surrounding_combos\n",
    "\n",
    "\n",
    "\n",
    "    def _get_new_cores(self, core):\n",
    "        \"\"\" Helper that gets new cores given old cores \"\"\"\n",
    "\n",
    "        # if (should be rare) case where core has been a core before, then skip. For prevention of infinite loops\n",
    "        # 2 means actual checked core, 1 means appended to checked core list but not checked\n",
    "        if self.checked_core[tuple(core)] == 2:\n",
    "            return\n",
    "        else:\n",
    "            self.checked_core[tuple(core)] = 2 # actually been checked as a core\n",
    "\n",
    "        surrounding_combos = self._get_surrounding_step_combos(core)\n",
    "\n",
    "        # actually tune the surrounding combos\n",
    "        for combo in surrounding_combos:\n",
    "            \n",
    "            if self.checked[tuple(combo)] == 0:\n",
    "                self._up_to += 1\n",
    "                self._train_and_test_combo(combo)\n",
    "            else:\n",
    "                print(f'\\tAlready Trained and Tested combination {combo}')\n",
    "\n",
    "        # perform welch test and return surrounding combos that should be used as new core\n",
    "        new_cores = self._find_new_core(surrounding_combos, core)\n",
    "\n",
    "        return new_cores  \n",
    "\n",
    "\n",
    "\n",
    "    def _GuidanceSystem(self, core):\n",
    "        \"\"\" Helper that performs guidance search \"\"\"\n",
    "\n",
    "        if self._restarts == 0:\n",
    "            print(\"Guidance: initial round \\n\")\n",
    "        else:\n",
    "            print(\"Guidance: round\", self._restarts, '\\n')\n",
    "\n",
    "        print('\\tround', self._restarts, 'iteration: ', 0, '\\n')\n",
    "\n",
    "        # first get a surrounding 3^d tuned\n",
    "        new_cores = self._get_new_cores(core)\n",
    "        self.been_cruised[tuple(core)] = 1 # represent don't need to be added as a to cruised - but not cruised, rather a core\n",
    "\n",
    "        round = 1\n",
    "        while new_cores: # while new cores are being added\n",
    "            print('\\tround', self._restarts, \"iteration: \", round, \"\\n\") \n",
    "            round += 1\n",
    "\n",
    "            old_new_cores = copy.deepcopy(new_cores)\n",
    "            new_cores = list()\n",
    "\n",
    "            # for each of the new cores, 'recursively' tune and grab new cores; but each Iteration doesn't end until all cores of current round has been checked\n",
    "            for new_core in old_new_cores:\n",
    "                \n",
    "                new_new_cores = self._get_new_cores(new_core)\n",
    "\n",
    "                if not new_new_cores:\n",
    "                    new_new_cores = []\n",
    "\n",
    "                self.been_cruised[tuple(core)] == 1\n",
    "                \n",
    "                for new_new_core in new_new_cores:\n",
    "                    if self.checked_core[tuple(new_new_core)] == 0:\n",
    "                        new_cores.append(new_new_core)\n",
    "                        self.checked_core[tuple(new_new_core)] = 1 # represent added to checked core - to prevent repeated added to core\n",
    "\n",
    "\n",
    "        # for current max, get 3^d block. if new max happens to be found, continue to do 3^d block until no new max is found\n",
    "        # just a cheap way to flesh out the max (the goal of PuDong)\n",
    "        while self.been_best[tuple(self.best_combo)] == 0:\n",
    "\n",
    "            self.been_best[tuple(self.best_combo)] = 1 \n",
    "    \n",
    "            surrounding_combos = self._get_surrounding_step_combos(self.best_combo)\n",
    "            for combo in surrounding_combos:\n",
    "                \n",
    "                if self.checked[tuple(combo)] == 0:\n",
    "                    self._up_to += 1\n",
    "                    self._train_and_test_combo(combo)\n",
    "                else:\n",
    "                    print(f'\\tAlready Trained and Tested combination {combo}')\n",
    "\n",
    "        # print information of this round \n",
    "\n",
    "        print('% Combos Checked Thus Far:', int(sum(self.checked.reshape((np.prod(self.n_items))))), 'out of', np.prod(self.n_items), 'which is', f'{np.mean(self.checked).round(8)*100}%')\n",
    "\n",
    "\n",
    "\n",
    "    def tune(self, key_stats_only = False):\n",
    "        \"\"\" Begin tuning \"\"\"\n",
    "\n",
    "        if self.train_x is None or self.train_y is None or self.val_x is None or self.val_y is None or self.test_x is None or self.test_y is None:\n",
    "            print(\" Missing one of the datasets, please run .read_in_data() \")\n",
    "            return\n",
    "\n",
    "        if self.model is None:\n",
    "            print(\" Missing model, please run .read_in_model() \")\n",
    "            return\n",
    "\n",
    "        if self.tuning_result_saving_address is None:\n",
    "            print(\"Missing tuning result csv saving address, please run ._save_tuning_result() first\")\n",
    "\n",
    "        self.key_stats_only = key_stats_only\n",
    "\n",
    "        print(\"BEGIN TUNING\\n\\n\") \n",
    "        \n",
    "        # FIRST: get all cruise combinations as well as core, and tune all these\n",
    "        self._get_core()\n",
    "        self._get_cruise_combinations() \n",
    "\n",
    "        first_round_combinations = copy.deepcopy(self._cruise_combinations)\n",
    "        first_round_combinations.append(self._core) \n",
    "\n",
    "        random.seed(self._seed)\n",
    "        random.shuffle(first_round_combinations)\n",
    "\n",
    "        print(\"STAGE ZERO: Tune all Cruise combinations\\n\\n\")\n",
    "        for combo in first_round_combinations:\n",
    "            \n",
    "            if not self.checked[tuple(combo)]:\n",
    "                self._up_to += 1\n",
    "                self._train_and_test_combo(combo)\n",
    "            \n",
    "            else:\n",
    "                print(f'\\tAlready Trained and Tested combination {combo}')\n",
    "        \n",
    "\n",
    "        # SECOND: from the core combo, begin guidance system\n",
    "        self._surrounding_vectors = self._get_surrounding_step_vectors(self._core)\n",
    "\n",
    "        print('\\n')\n",
    "        print(\"STAGE ONE: Begin initial Guidance system\\n\\n\")\n",
    "\n",
    "        self._restarts = 0\n",
    "        self._GuidanceSystem(self._core) # Initial Round of Guidance\n",
    "        self._restarts += 1\n",
    "\n",
    "        # THIRD: Recursively Cruise and restart Guide if find a combo that is within halfwidth of mean of best combo surrounds\n",
    "        print(\"STAGE TWO: Begin Cruise system\\n\\n\")\n",
    "        self._cruising = True\n",
    "        while self._cruising:\n",
    "            suspicious_case_combo = self._CruiseSystem()\n",
    "\n",
    "            if self._cruising:\n",
    "                self._GuidanceSystem(tuple(suspicious_case_combo))\n",
    "                self._restarts += 1\n",
    "\n",
    "        # FINALLY: Final extensive guidance search around maxes.\n",
    "        print(\"FINAL STAGE: Begin final Guidance system\\n\\n\")\n",
    "        old_best_score = copy.deepcopy(self.best_score)\n",
    "        self._restarts = 'FINAL'\n",
    "\n",
    "        self._GuidanceSystem(self.best_combo)\n",
    "\n",
    "        while(self.best_score-old_best_score > 0):\n",
    "            old_best_score = copy.deepcopy(self.best_score)\n",
    "            self._GuidanceSystem(self.best_combo)\n",
    "\n",
    "\n",
    "\n",
    "        # Display final information\n",
    "        print(\"TUNING FINISHED\\n\")\n",
    "\n",
    "        print('Max Score: \\n', self.best_score)\n",
    "        print('Max Combo: \\n', self.best_combo)\n",
    "\n",
    "        print('% Combos Checked:', int(sum(self.checked.reshape((np.prod(self.n_items))))), 'out of', np.prod(self.n_items), 'which is', f'{np.mean(self.checked).round(8)*100}%')\n",
    "    \n",
    "\n",
    "\n",
    "    def _train_and_test_combo(self, combo):\n",
    "        \"\"\" Helper to train and test each combination as part of tune() \"\"\"\n",
    "\n",
    "        combo = tuple(combo)\n",
    "        \n",
    "        params = {self.hyperparameters[i]:self.parameter_choices[self.hyperparameters[i]][combo[i]] for i in range(len(self.hyperparameters))}\n",
    "        \n",
    "        \n",
    "        if self._tune_features == True:\n",
    "            del params['features']\n",
    "            tmp_train_x = self.train_x[list(self.feature_combo_n_index_map[combo[-1]])] \n",
    "            tmp_val_x = self.val_x[list(self.feature_combo_n_index_map[combo[-1]])]\n",
    "            tmp_test_x = self.test_x[list(self.feature_combo_n_index_map[combo[-1]])]\n",
    "\n",
    "            # add non tuneable parameters\n",
    "            for nthp in self.non_tuneable_parameter_choices:\n",
    "                params[nthp] = self.non_tuneable_parameter_choices[nthp]\n",
    "\n",
    "            # initialise object\n",
    "            clf = self.model(**params)\n",
    "\n",
    "            params['features'] = [list(self.feature_combo_n_index_map[combo[-1]])] \n",
    "            params['feature combo ningxiang score'] = self.feature_n_ningxiang_score_dict[self.feature_combo_n_index_map[combo[-1]]]\n",
    "\n",
    "        else:\n",
    "            tmp_train_x = self.train_x\n",
    "            tmp_val_x = self.val_x\n",
    "            tmp_test_x = self.test_x\n",
    "\n",
    "            # add non tuneable parameters\n",
    "            for nthp in self.non_tuneable_parameter_choices:\n",
    "                params[nthp] = self.non_tuneable_parameter_choices[nthp]\n",
    "\n",
    "            # initialise object\n",
    "            clf = self.model(**params)\n",
    "\n",
    "        # get time and fit\n",
    "        start = time.time()\n",
    "        clf.fit(tmp_train_x, self.train_y)\n",
    "        end = time.time()\n",
    "\n",
    "        # get predicted labels/values for three datasets\n",
    "        train_pred = clf.predict(tmp_train_x)\n",
    "        val_pred = clf.predict(tmp_val_x)\n",
    "        test_pred = clf.predict(tmp_test_x)\n",
    "\n",
    "        # get scores and time used\n",
    "        time_used = end-start\n",
    "\n",
    "        # build output dictionary and save result\n",
    "        df_building_dict = params\n",
    "        for nthp in self.non_tuneable_parameter_choices:\n",
    "            del params[nthp] \n",
    "\n",
    "\n",
    "        if self.clf_type == 'Regression':\n",
    "\n",
    "            train_score = val_score = test_score = train_rmse = val_rmse = test_rmse = train_mape = val_mape = test_mape = 0\n",
    "\n",
    "            try:\n",
    "                train_score = r2_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_score = r2_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_score = r2_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_rmse = np.sqrt(mean_squared_error(self.train_y, train_pred))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_rmse = np.sqrt(mean_squared_error(self.val_y, val_pred))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_rmse = np.sqrt(mean_squared_error(self.test_y, test_pred))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if self.key_stats_only == False:\n",
    "                try:\n",
    "                    train_mape = mean_absolute_percentage_error(self.train_y, train_pred)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    val_mape = mean_absolute_percentage_error(self.val_y, val_pred)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    test_mape = mean_absolute_percentage_error(self.test_y, test_pred)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            df_building_dict['Train r2'] = [np.round(train_score, 6)]\n",
    "            df_building_dict['Val r2'] = [np.round(val_score, 6)]\n",
    "            df_building_dict['Test r2'] = [np.round(test_score, 6)]\n",
    "            df_building_dict['Train RMSE'] = [np.round(train_rmse, 6)]\n",
    "            df_building_dict['Val RMSE'] = [np.round(val_rmse, 6)]\n",
    "            df_building_dict['Test RMSE'] = [np.round(test_rmse, 6)]\n",
    "            \n",
    "            if self.key_stats_only == False:\n",
    "                df_building_dict['Train MAPE'] = [np.round(train_mape, 6)]\n",
    "                df_building_dict['Val MAPE'] = [np.round(val_mape, 6)]\n",
    "                df_building_dict['Test MAPE'] = [np.round(test_mape, 6)]\n",
    "\n",
    "        \n",
    "        elif self.clf_type == 'Classification':\n",
    "\n",
    "            train_score = val_score = test_score = train_bal_accu = val_bal_accu = test_bal_accu = train_f1 = val_f1 = test_f1 = \\\n",
    "                train_precision = val_precision = test_precision = train_recall = val_recall = test_recall = 0\n",
    "\n",
    "            try:    \n",
    "                train_score = accuracy_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_score = accuracy_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_score = accuracy_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                train_bal_accu = balanced_accuracy_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_bal_accu = balanced_accuracy_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_bal_accu = balanced_accuracy_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_f1 = f1_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_f1 = f1_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_f1 = f1_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_precision = precision_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_precision = precision_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_precision = precision_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                train_recall = recall_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_recall = recall_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_recall = recall_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            df_building_dict['Train accu'] = [np.round(train_score, 6)]\n",
    "            df_building_dict['Val accu'] = [np.round(val_score, 6)]\n",
    "            df_building_dict['Test accu'] = [np.round(test_score, 6)]\n",
    "            df_building_dict['Train balanced_accuracy'] = [np.round(train_bal_accu, 6)]\n",
    "            df_building_dict['Val balanced_accuracy'] = [np.round(val_bal_accu, 6)]\n",
    "            df_building_dict['Test balanced_accuracy'] = [np.round(test_bal_accu, 6)]\n",
    "            df_building_dict['Train f1'] = [np.round(train_f1, 6)]\n",
    "            df_building_dict['Val f1'] = [np.round(val_f1, 6)]\n",
    "            df_building_dict['Test f1'] = [np.round(test_f1, 6)]\n",
    "            df_building_dict['Train precision'] = [np.round(train_precision, 6)]\n",
    "            df_building_dict['Val precision'] = [np.round(val_precision, 6)]\n",
    "            df_building_dict['Test precision'] = [np.round(test_precision, 6)]\n",
    "            df_building_dict['Train recall'] = [np.round(train_recall, 6)]\n",
    "            df_building_dict['Val recall'] = [np.round(val_recall, 6)]\n",
    "            df_building_dict['Test recall'] = [np.round(test_recall, 6)]\n",
    "\n",
    "\n",
    "        df_building_dict['Time'] = [np.round(time_used, 2)]\n",
    "\n",
    "\n",
    "        tmp = pd.DataFrame(df_building_dict)\n",
    "\n",
    "\n",
    "        self.tuning_result = self.tuning_result.append(tmp)\n",
    "        self._save_tuning_result()\n",
    "\n",
    "        # update best score stats\n",
    "        if val_score > self.best_score: \n",
    "            self.best_score = val_score\n",
    "            self.best_clf = clf\n",
    "            self.best_combo = combo\n",
    "\n",
    "        # update internal governing DataFrames\n",
    "        self.checked[combo] = 1\n",
    "        self.result[combo] = val_score\n",
    "\n",
    "        print(f'''Trained and Tested combination {self._up_to} of {self._total_combos}: {combo}, taking {time_used} seconds to get val score of {val_score}\n",
    "        Current best combo: {self.best_combo} with val score {self.best_score}''')\n",
    "\n",
    "\n",
    "                \n",
    "    def _save_tuning_result(self):\n",
    "        \"\"\" Helper to export tuning result csv \"\"\"\n",
    "\n",
    "        tuning_result_saving_address_split = self.tuning_result_saving_address.split('.csv')[0]\n",
    "\n",
    "        self.tuning_result.to_csv(f'{tuning_result_saving_address_split}.csv', index=False)\n",
    "\n",
    "    \n",
    "\n",
    "    def view_best_combo_and_score(self):\n",
    "        \"\"\" View best combination and its validation score \"\"\"\n",
    "        \n",
    "        print(f'(Current) Best combo: {self.best_combo} with val score {self.best_score}')\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_tuning_result_df(self, address): \n",
    "        \"\"\" Read in tuning result csv and read data into checked and result arrays \"\"\"\n",
    "\n",
    "        if self.parameter_choices is None:\n",
    "            print(\"Missing parameter_choices to build parameter_value_map_index, please run set_hyperparameters() first\")\n",
    "\n",
    "        if self.clf_type is None:\n",
    "            print('Missing clf_type. Please run .read_in_model() first.')\n",
    "\n",
    "        self.tuning_result = pd.read_csv(address)\n",
    "        print(f\"Successfully read in tuning result of {len(self.tuning_result)} rows\")\n",
    "\n",
    "        self._up_to = 0\n",
    "\n",
    "        self._create_parameter_value_map_index()\n",
    "\n",
    "        # read DataFrame data into internal governing DataFrames of PuDong\n",
    "        for row in self.tuning_result.iterrows():\n",
    "\n",
    "            self._up_to += 1\n",
    "    \n",
    "            combo = tuple([self.parameter_value_map_index[hyperparam][row[1][hyperparam]] for hyperparam in self.hyperparameters])\n",
    "            \n",
    "            self.checked[combo] = 1\n",
    "            \n",
    "            if self.clf_type == 'Regression':\n",
    "                self.result[combo] = row[1]['Val r2']\n",
    "            elif self.clf_type == 'Classification':\n",
    "                self.result[combo] = row[1]['Val accu']\n",
    "        \n",
    "            # update best score stats\n",
    "            if self.result[combo] > self.best_score: \n",
    "                self.best_score = self.result[combo]\n",
    "                self.best_clf = None\n",
    "                print(f\"As new Best Combo {combo} is read in, best_clf is set to None\")\n",
    "                self.best_combo = combo\n",
    "\n",
    "\n",
    "    \n",
    "    def _create_parameter_value_map_index(self):\n",
    "        \"\"\" Helper to create parameter-value index map \"\"\"\n",
    "\n",
    "        self._parameter_value_map_index = dict()\n",
    "        for key in self.parameter_choices.keys():\n",
    "            tmp = dict()\n",
    "            for i in range(len(self.parameter_choices[key])):\n",
    "                tmp[self.parameter_choices[key][i]] = i\n",
    "            self._parameter_value_map_index[key] = tmp\n",
    "\n",
    "\n",
    "    \n",
    "    def set_tuning_result_saving_address(self, address):\n",
    "        \"\"\" Read in where to save tuning object \"\"\"\n",
    "\n",
    "        self.tuning_result_saving_address = address\n",
    "        print('Successfully set tuning output address')\n",
    "\n",
    "\n",
    "\n",
    "    def _set_object_saving_address(self, address):\n",
    "        \"\"\" Read in where to save the PuDong object \"\"\"\n",
    "\n",
    "        self.object_saving_address = address\n",
    "        print('Successfully set object output address')\n",
    "\n",
    "\n",
    "\n",
    "    def export_pudong(self, address):\n",
    "        \"\"\" Export PuDong object \"\"\"\n",
    "\n",
    "        self._set_object_saving_address(address)\n",
    "\n",
    "        # copy object and set big objects to None\n",
    "        object_save = copy.deepcopy(self)\n",
    "        \n",
    "        object_save.train_x = None\n",
    "        object_save.train_y = None\n",
    "        object_save.val_x = None\n",
    "        object_save.val_y = None\n",
    "        object_save.test_x = None\n",
    "        object_save.test_y = None\n",
    "\n",
    "        # Export\n",
    "        object_saving_address_split = self.object_saving_address.split('.pickle')[0]\n",
    "\n",
    "        with open(f'{object_saving_address_split}.pickle', 'wb') as f:\n",
    "            pickle.dump(object_save, f)\n",
    "\n",
    "        print(f'Successfully exported PuDong object as {self.object_saving_address}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
